# 文档说明

本文档主要分享求职面试题。文档目前还在持续更新中，欢迎关注、收藏、点赞、加星喔😄O(∩_∩)O~。

同一个面试题往往会有很多种不同的问法，为了方便大家搜索，本文中面试题标题将尽量简洁，以涵盖同一面试题的不同问法。

| 文档名称     | 求职-面试题-微服务 |
| ------------ | ------------------ |
| 文档分类     | 求职-面试题        |
| 版本号       | 1.0                |
| 最后更新人   | Gem Shen           |
| 最后更新日期 | 2024-02-27         |
| 创建人       | Gem Shen           |
| 创建日期     | 2024-02-27         |



# 微服务公共

## 架构概念

### 微服务和分布式有什么区别？

分布式是将一个集中式的大系统拆分成多个子系统，每个系统对外提供部分功能。整个分布式系统对外提供一整套的服务。

对于用户来说，其实并不知道分布式系统到底有多少个子系统，占用多少个服务器。

分布式架构也有很多种，包含C/S架构，P2P架构，SOA架构，微服务架构，Serverless架构等。所以微服务只是分布式架构的其中一种。



### 微服务和SOA的区别？

微服务架构（Microservices Architecture）和面向服务架构（Service-Oriented Architecture，SOA）都是一种用于构建分布式系统的架构风格，但它们之间有一些关键的区别：

1. **粒度不同：**
   - **微服务架构：** 微服务架构将应用程序拆分为一组小型、独立的服务，每个服务都专注于执行特定的业务功能。每个微服务都是独立部署和扩展的，可以使用不同的技术栈来实现。微服务的粒度更小，通常以功能模块为单位。
   - **SOA架构：** 面向服务架构也是将应用程序拆分为服务的方式，但服务的粒度相对较大，通常是以业务功能为单位。SOA架构中的服务可以被多个应用程序共享，服务的复用性更强。
2. **通信方式不同：**
   - **微服务架构：** 微服务之间通常通过轻量级的HTTP RESTful API进行通信，每个微服务都可以独立部署和扩展。微服务之间的通信更加灵活和简单。
   - **SOA架构：** SOA架构中的服务通常通过企业服务总线（ESB）或消息队列进行通信，服务之间的集成更加复杂。
3. **数据管理方式不同：**
   - **微服务架构：** 每个微服务通常有自己的数据库，服务之间的数据是分散存储的。微服务架构鼓励每个服务拥有自己的数据存储，以提高服务的自治性和独立性。
   - **SOA架构：** SOA架构中的服务通常共享一个中央数据库或数据仓库，服务之间的数据共享更为直接。
4. **部署和扩展方式不同：**
   - **微服务架构：** 微服务可以独立部署和扩展，每个微服务都有自己的生命周期和版本控制。微服务架构更加灵活和容易扩展。
   - **SOA架构：** SOA架构中的服务通常需要协同部署，服务之间的版本管理和升级更为复杂。

总的来说，微服务架构更加注重服务的独立性、自治性和灵活性，适合构建复杂的分布式系统。而SOA架构更加注重服务的复用性和集成性，适合构建企业级应用和服务。选择合适的架构取决于具体的应用需求和复杂度。



### CAP理论介绍

CAP理论（CAP theorem）指出对于一个分布式计算系统，不可能同时满足以下三个特性：

- **一致性 (Consistency)**：分布式系统中所有节点在同一时刻看到的系统状态都是一致的。
  - 例如：分布式银行系统中，A向B转账50。当转账成功后，所有节点中的数据应该是一致的。
  - 为了实现一致性，需要用到分布式锁在操作前锁定数据。操作完成后要等待数据同步到所有节点上。
- **可用性 (Availability)**：系统在任何时刻都必须能够响应请求，不会出现不可用的情况。
- **分区容错性 (Partition Tolerance)**：即使系统中的某些节点出现故障或网络分区，系统仍能继续运行。
  - 例如：存在A，B，C3个节点，A为主节点，当A崩溃后，要从B和C中选举出主节点，系统此时无法响应不满足A，但满足P。

根据CAP理论，分布式系统只能同时满足其中两个特性，而不能同时满足三个特性。且只能从CP或AP中选择。即P是必须保证的。



### BASE理论介绍

BASE理论是对CAP理论的延伸，核心思想是即使无法做到强一致性(Strong Consistency，CAP的一致性就是强一致性)，但应用可以采用适合的方式达到最终一致性(EventualConsitency)。

BASE是指基本可用(Basically Available)、软状态(Soft State)、最终一致性(Eventual Consistency)。

做不到100%可用，那么就做到基本可用。做不到强一致性，那么就做到最终一致性。

想要做到BASE，那么主要就是用这几个手段:中间状态(软状态)+重试(最终一致性)+降级(基本可用)

- 基本可用

  基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性—-注意，这绝不等价于系统不可用。比如：

  （1）响应时间上的损失。正常情况下，一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结果，但由于出现故障，查询结果的响应时间增加了1~2秒

  （2）系统功能上的损失：正常情况下，在一个电子商务网站上进行购物的时候，消费者几乎能够顺利完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面

- 软状态

  软状态指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时

- 最终一致性

  最终一致性强调的是所有的数据副本，在经过一段时间的同步之后，最终都能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。





### 什么是Serverless架构？使用场景

Serverless架构是一种云计算模型，其核心思想是开发者无需关心服务器的管理和维护，只需关注编写和部署函数（Function）即可。Serverless架构将计算资源的管理交给云服务提供商，根据实际的请求量和使用情况动态分配资源，实现弹性扩展和按需付费。使用Serverless架构可以极大地简化开发流程、降低成本并提高效率。

一些常见的Serverless平台包括AWS Lambda、Azure Functions、Google Cloud Functions等，它们提供了丰富的功能和工具，帮助开发者快速构建和部署无服务器应用。

使用场景如下：

1. **Web应用开发：** Serverless架构适合用于构建轻量级的Web应用，如静态网站、博客等。开发者可以使用Serverless函数来处理前端请求并返回相应的数据。
2. **数据处理和分析：** Serverless平台可以用于数据清洗、数据分析、ETL处理等场景。开发者可以编写函数来处理大规模数据，并根据需要动态扩展计算资源。
3. **后端服务：** Serverless函数可以用作后端服务的一部分，处理业务逻辑、数据库访问等功能。这种方式可以减少服务器管理的复杂性，并实现按需扩展。
4. **事件驱动的应用：** Serverless架构适合开发事件驱动的应用，如处理实时数据流、处理消息队列等场景。开发者可以编写函数来响应不同的事件触发。
5. **IoT应用：** Serverless函数可以用于处理IoT设备发送的数据，进行实时处理和分析。这种方式可以实现快速响应和实时处理。

总的来说，Serverless架构适用于需要快速开发、高可伸缩性、低成本的应用场景。通过使用Serverless架构，开发者可以专注于业务逻辑的实现，而无需关心基础设施的管理和维护，从而加快开发速度并降低运维成本。



### 康威定律是什么？

康威定律（Conway's Law）是由计算机科学家梅尔文·康威于1967年提出的，它指出：

**“设计系统的组织与该系统的架构之间存在着必然的对应关系。”**

换句话说，一个系统的架构往往会反映出设计和构建该系统的组织的结构和沟通方式。

康威定律的含义是，如果一个组织的沟通和决策流程是分散和模块化的，那么它所设计的系统也往往是模块化和松散耦合的。相反，如果一个组织的沟通和决策流程是集中和等级式的，那么它所设计的系统也往往是集中式和紧密耦合的。

康威定律对软件开发有重要的影响，它表明软件架构应该与开发团队的组织结构相匹配。例如，如果一个开发团队是由多个独立的小组组成的，那么软件架构应该被设计成模块化的，以便每个小组可以独立地开发和维护自己的模块。

康威定律也适用于其他领域，如组织设计、产品开发和业务流程。它表明，组织的结构和流程会对所创建的产品和服务产生深远的影响。

需要注意的是，康威定律并不是一个严格的定律，而是更多地作为一个经验法则。在某些情况下，组织的结构和沟通方式可能会与系统的架构不一致。然而，康威定律仍然是一个有用的工具，可以帮助组织了解其结构和流程如何影响其所创建的系统。



### 熔断限流降级

**熔断**

熔断是一种保护系统免受级联故障影响的机制。当系统检测到错误率过高时，熔断器会“熔断”，切断对受影响组件或服务的访问。这可以防止错误进一步传播并导致整个系统崩溃。

熔断器通常具有以下状态：

- **关闭：**熔断器已熔断，拒绝所有请求。
- **打开：**熔断器已复位，允许请求通过。
- **半开：**熔断器允许少量请求通过，以测试系统是否已恢复。

**限流**

限流是一种限制系统中并发请求数量的机制。这可以防止系统因过载而崩溃。限流器通常使用令牌桶或漏桶算法来控制请求速率。

- **令牌桶：**限流器有一个固定大小的令牌桶。每个请求都需要一个令牌才能通过。如果桶中没有令牌，则请求将被丢弃。
- **漏桶：**限流器有一个固定速率的漏桶。请求以恒定速率进入漏桶。如果漏桶已满，则请求将被丢弃。

**降级**

降级是一种在系统过载时降低服务质量的机制。这可以防止系统完全崩溃，并允许用户继续使用部分功能。降级通常涉及禁用非关键功能或降低服务质量。

例如，在电子商务网站上，降级可能涉及：

- 禁用产品搜索功能
- 降低图像质量
- 增加页面加载时间

**熔断、限流和降级的区别**

| 特征     | 熔断                   | 限流               | 降级                         |
| -------- | ---------------------- | ------------------ | ---------------------------- |
| 目的     | 保护系统免受级联故障   | 防止系统过载       | 在过载时降低服务质量         |
| 机制     | 切断对受影响组件的访问 | 限制并发请求的数量 | 禁用非关键功能或降低服务质量 |
| 触发条件 | 错误率过高             | 并发请求数量过高   | 系统过载                     |
| 恢复方式 | 手动或自动复位         | 根据算法自动恢复   | 手动或自动恢复               |

**总结**

熔断、限流和降级都是保护分布式系统免受故障和过载影响的重要机制。熔断器通过切断对受影响组件的访问来防止级联故障。限流器通过限制并发请求的数量来防止系统过载。降级通过降低服务质量来防止系统完全崩溃。



### 灰度发布、蓝绿部署、金丝雀部署

灰度发布（Canary Release）、蓝绿部署（Blue-Green Deployment）和金丝雀部署（Canary Deployment）都是软件部署和发布的策略，用于降低发布新版本对系统稳定性和用户体验的影响。

1. 灰度发布（Canary Release）：灰度发布是一种逐步将新版本发布到生产环境的策略。在灰度发布中，新版本会先被部署到一小部分用户或服务器上，然后根据新版本的稳定性和性能逐步扩大发布范围，直到完全替换旧版本。这种方式可以在发布新版本后监测系统的稳定性，及时发现并解决问题，最大程度地减少对整个系统的影响。
2. 蓝绿部署（Blue-Green Deployment）：蓝绿部署是一种通过在两个独立的生产环境中交替部署新旧版本的策略。在蓝绿部署中，一个环境（比如蓝色环境）运行当前稳定的旧版本，另一个环境（比如绿色环境）运行新版本。当新版本部署完成并通过测试后，流量会逐步切换到新版本环境，从而实现无缝的系统切换。
3. 金丝雀部署（Canary Deployment）：金丝雀部署是一种在生产环境中逐步引入新版本的策略。在金丝雀部署中，新版本会先被部署到一小部分用户或服务器上，然后根据新版本的性能和用户反馈逐步扩大部署范围。这种方式可以在发布新版本后快速获得反馈，及时发现潜在问题，并在影响范围有限的情况下进行回滚或修复。

这些部署策略都旨在降低发布新版本时的风险，保证系统的稳定性和可靠性，同时尽可能减少对用户的影响。选择合适的部署策略取决于具体的系统需求和发布流程。



## 框架实现

### SpringCloud介绍

Spring Cloud是基于Spring Boot的分布式系统开发工具，它提供了一系列开箱即用的、针对分布式系统开发的特性和组件，用于帮助开发人员快速构建和管理云原生应用程序。

Spring Cloud的主要目标是解决分布式系统中的常见问题，例如服务发现、负载均衡、配置管理断路器、消息总线等。

所以，单体应用使用Spring，需要快速构建，简化开发使用SpringBoot，构建分布式、微服务应用，使用SpringCloud。

[SpringCloud架构图]: https://www.processon.com/embed/65ed7ace9a343d3e89b56db1

SpringCloud组件介绍

1. Eureka:服务发现和注册中心，可以帮助服务消费者自动发现和调用服务提供者

2. Ribbon:负载均衡组件，可以帮助客户端在多个服务提供者之间进行负载均衡。
3. OpenFeign:声明式HTTP客户端，可以帮助开发人员更容易地编写HTTP调用代码。
4. Hystrix:断路器组件，可以帮助应用程序处理服务故障和延迟问题,



### SpringCloudTencent介绍

Spring Cloud Tencent 是腾讯开源的一站式微服务解决方案。

Spring Cloud Tencent 实现了Spring Cloud 标准微服务 SPI，开发者可以基于 Spring CloudTencent 快速开发 Spring Cloud 云原生分布式应用。

Spring Cloud Tencent提供的能力包括但不限于:

![](https://static.oschina.net/uploads/space/2022/0620/175942_r9HK_4252687.png)



### Dubbo和SpringCloud的区别

**Spring Cloud** 和 **Dubbo** 都是流行的微服务框架，但它们在设计理念、架构和功能方面存在一些关键区别：

**设计理念：**

- **Spring Cloud：** 基于 Spring Boot 和 Spring Framework，强调松散耦合和敏捷开发。
- **Dubbo：** 基于 Java 虚拟机（JVM），强调高性能和稳定性。

**架构：**

- **Spring Cloud：** 采用分布式系统架构，使用服务发现、负载均衡和配置管理等组件。
- **Dubbo：** 采用集中式架构，使用中央注册中心和服务治理组件。

**功能：**

- **Spring Cloud：** 提供全面的微服务功能，包括服务发现、负载均衡、配置管理、熔断器和分布式跟踪。
- **Dubbo：** 主要专注于服务治理，提供高性能的远程过程调用（RPC）框架、服务发现和负载均衡。

**其他区别：**

- **语言支持：** Spring Cloud 支持多种编程语言，包括 Java、Kotlin 和 Groovy。Dubbo 主要支持 Java。
- **社区支持：** Spring Cloud 拥有庞大且活跃的社区，而 Dubbo 主要在中国流行。
- **商业支持：** Spring Cloud 由 Pivotal 提供商业支持，而 Dubbo 由阿里巴巴提供商业支持。

**适用场景：**

- **Spring Cloud：** 适用于需要快速开发和部署微服务的场景，尤其是在需要跨语言支持和全面功能的情况下。
- **Dubbo：** 适用于需要高性能和稳定性的场景，尤其是在 Java 生态系统中。

**Dubbo的实际业务场景**

- **阿里巴巴：** 阿里巴巴集团广泛使用 Dubbo 来构建其庞大的电子商务平台，包括淘宝、天猫和支付宝。Dubbo 为阿里巴巴提供了高性能、可扩展和稳定的服务治理解决方案。
- **携程：** 携程使用 Dubbo 来构建其在线旅游预订平台。Dubbo 帮助携程实现了高并发、低延迟和高可用性的服务调用。
- **京东：** 京东使用 Dubbo 来构建其物流和供应链管理系统。Dubbo 为京东提供了灵活、可扩展和可靠的服务治理解决方案。
- **滴滴出行：** 滴滴出行使用 Dubbo 来构建其打车和外卖服务平台。Dubbo 帮助滴滴出行实现了高并发、低延迟和高可用的服务调用。
- **网易：** 网易使用 Dubbo 来构建其游戏和音乐流媒体平台。Dubbo 为网易提供了高性能、可扩展和稳定的服务治理解决方案。



**总结：**

Spring Cloud 和 Dubbo 都是优秀的微服务框架，但它们适合不同的场景和需求。Spring Cloud 强调敏捷开发和全面功能，而 Dubbo 强调高性能和稳定性。



# 负载均衡

## 对比选型

### Nginx和Ribbon的区别

Nginx是一种服务端负载均衡的解决方案，而Ribbon是一种客户端负载均衡的解决方案。

Nginx 位于客户端和后端服务器之间，将客户端请求转发到适当的后端服务器。它使用轮询或其他负载均衡算法来分发请求。

Ribbon 则集成到服务消费端的代码中且仅适用于 Java 应用程序，性能可能不如Nginx。而Nginx则用于 HTTP/HTTPS 流量负载均衡

如果客户端应用程序有多个节点，则可以为每个节点单独配置 Ribbon 的负载均衡策略。

适用场景上，Nginx 适用于需要高性能和可扩展性的 HTTP/HTTPS 流量负载均衡，而 Ribbon 适用于需要高级服务发现和故障转移机制的微服务架构中的客户端负载均衡。

负载均衡策略上，nginx不支持加权轮询，随机，基于规则的路由。Ribbon不支持：基于服务器名称哈希和ip哈希。



### LoadBalance和Ribbon的区别

Ribbon是Netfix推出的负载均衡组件，但是从2020年开始，Netfix推出的很多SpringCloud组件都宣布不再更新维护了，所以，SpringCloud就自己推出了Spring Cloud LoadBalancer 来代替Ribbon，所以，在SpringCloud 2020.0版本中，Ribbon已经被标记为过时，官方推荐使用Spring Cloud LoadBalancer。

LoadBalancer的使用方式与Ribbon基本兼容可以从Ribbon进行平滑过渡。

LoadBalancer是Ribbon的替代品，二者在功能和使用上没什么太大的差别，如果非要说的话，区别如下:

- 实现方式:Ribbon是一个独立的第三方的库，需要单独引入。而Spring Cloud LoadBalancer是SpringCloud的一个组件，集成在Spring Cloud中，可以直接使用。
- 易用性:Ribbon是一个较为底层的负载均衡器，需要开发人员手动配置负载均衡策略和服务发现机制。而Spring Cloud LoadBalancer提供了一个更高层次的抽象，将负载均衡策略和服务发现机制的实现进行了封装，使开发人员更容易使用。
- 生态完整:Spring Cloud LoadBalancer与Spring Cloud的其他组件紧密集成，具有更好的易用性和稳定性，而且与Ribbon相比，更加轻量级，性能更好。







# 网关

## 对比选型

### Zuul，Gateway、Nginx的区别

这些都是常用的网关和反向代理。

Zuul是Netfix开源的一个服务网关，它提供了动态路由、负载均衡、请求过滤、身份验证、安全性等功能。Zuul通常与Netflix的Eureka服务发现框架结合使用，并通过配置路由规则将请求路由到适当的后端服务。

Gateway是Spring Cloud的一部分，用于构建基于Spring Boot的微服务网关。它提供了类似于Zuul的功能，如路由、负载均衡、请求过滤、安全性等。当我们在微服务架构中，选择一个微服务网关的时候，**建议优先考虑Spring Cloud Gateway**，主要是因为Gatewav的推出就是要代替Zuul的，首先Gateway是Spring官方自己出的，而Zuul是Netflix出的，而且Gateway之所以推出，也是因为Zuul的更新和维护并不理想。而且Gateway使用Spring WebFlux框架和Reactor库，采用异步非阻塞的处理模型，所以性能会更好一些。它可以与Spring Cloud的服务注册与发现组件(如Eureka或Consul)进行集成。

Nginx是一个高性能的开源Web服务器和反向代理服务器。虽然Nginx本身并不是专门设计用作网关，但它经常被用作反向代理和负载均衡器，以提供网关功能。Nginx能够处理并转发HTTP、HTTPS、SMTP、POP3和IMAP等协议的请求，具有强大的性能和高并发处理能力。Nginx还支持基于配置的路由和请求过滤功能，可以根据请求的URL路径或其他条件将流量路由到后端服务器。

Zuul和Gateway是专门用于构建微服务架构的服务网关，提供了丰富的功能和易于配置的路由规则。而Nginx是一个通用的Web服务器和反向代理服务器，可以用作网关，但不像Zuul和Gateway那样专注于微服务架构。



# 注册中心

## 对比选型

### 注册中心对比选型

Zookeeper是最早流行的开源分布式协调服务框架之一，同时也提供了分布式配置中心的功能。Zookeeper以高可用、一致性和可靠性著称，但是需要用户自己来开发实现分布式配置的功能。

Nacos是阿里巴巴开源的服务注册中心和配置中心。与Zookeeper不同的是，Nacos自带了配置中心功能，并提供了更多的可视化配置管理工具。Nacos的目标是成为一个更全面的云原生服务发现、配置和管理平台。

Eureka是Netflix开源的服务注册中心，被广泛应用在Spring Cloud微服务架构中。它提供了易于使用的RESTAPI和Web界面，并支持基于Reqion和Zone的服务分组和负载均衡。

Consul是HashiCorp开源的服务注册中心和配置中心，提供了服务发现、健康检査、KV存储和多数据中心功能.

Consul提供了更丰富的健康检查和路由功能，同时也提供了丰富的API和Web Ul。

如果对一致性要求高，建议考虑支持CP模型的Consul、Nacos以及ZK

如果应用已经在使用Spring Cloud框架，则建议使用Eureka;

如果应用在用Dubbo/Spring Cloud Alibaba，或者需要一套更全面的云原生服务治理平台，则建议使用Nacos:

| 服务注册与发现框架 | CAP模型 | 控制台管理 | 社区活跃度      | 雪崩保护 | 协议     |
| ------------------ | ------- | ---------- | --------------- | -------- | -------- |
| Eureka             | AP      | 支持       | 低(2.x版本闭源) | 有       | Http     |
| Zookeeper          | CP      | 不支持     | 中              | 无       | TCP      |
| Consul             | CP      | 支持       | 高              | 无       | Http/DNS |
| Nacos              | AP/CP   | 支持       | 高              | 有       | Http/DNS |

如果需要更强大的健康检查和路由功能，则建议使用Consul。虽然Nacos和Eureka都支持服务健康检查和路由功能，但是Consul在这方面的功能更为强大，比如Consul支持多种健康检査方式(TCP、HTTP、GRPC等)、支持自定义健康检查脚本，可以更精细地控制服务的健康状况。

当然，Zookeeper也是一款成熟的分布式协调服务框架，如果已经熟悉使用Zookeeper，也可以考虑使用Zookeeper作为服务注册中心和配置中心。



## Nacos

### Nacos的作用

配置管理：可以将应用程序的配置信息存储在Nacos的配置中心，通过Nacos实现动态配置管理和灰度发布，从而实现应用程序的动态调整和部署。

服务发现及注册：可以将服务注册到Nacos注册中心，并通过Nacos实现服务的自动发现和负载均衡，从而实现服务的高可用和弹性伸缩。

服务治理：可以通过Nacos实现服务的健康检査、故障转移、服务限流、熔断降级等治理能力，从而提高服务的可靠性和稳定性。

事件监听和推送：可以通过Nacos实现配置变更、服务注册和注销等事件的监听和推送，从而实现应用程序的自动化部署和管理。



### Nacos是ap还是cp

Nacos支持AP和CP两种模式，可以根据具体的使用场景进行选择。默认情况下是AP模式，可以通过修改nacos的配置文件来切换AP/CP。
在AP模式下，Nacos保证高可用性和可伸缩性，但不保证强一致性。在CP模式下，Nacos保证强一致性，但可能会降低可用性和可伸缩性。

在实际应用中，具体应该采用哪种模式，需要根据业务的特点和需求来判断

如果在分布式系统中，某些数据的一致性对业务有非常高的要求，例如金融、支付等场景，那么可以选择使用CP模式。在CP模式下，当发生网络分区或故障时，为了保证数据一致性，Nacos会对服务进行自动隔离和恢复。但是，这会导致部分服务不可用，因此可用性会受到影响。

如果对于某些服务来说，可用性比一致性更加重要，例如网站、在线游戏等场景，那么可以选择使用AP模式。在AP模式下，Nacos会优先保证服务的可用性，如果发生了网络分区或故障，Nacos会在保证一定的可用性的前提下，尽可能保持数据一致性。这样虽然可能会导致数据不一致的情况，但是可以保证服务的可用性，从而减少业务的影响。



## Zookeeper





## GateWay

### gateway实现原理，画图



# 分布式事务

## Seata

### Seata介绍，有几种模式

Seata是一个阿里开源的分布式事务解决方案(Simple Extensible Autonomous Transaction Architecture)用于在分布式系统中实现分布式事务。它旨在简化分布式事务的开发和管理，帮助解决分布式系统中的数据一致性问题。

Seata目前支持4种模式，分别是:

AT模式，TCC模式，Saga模式，XA模式

#### AT模式（自动补偿事务）

- **原理**：基于本地ACID事务，通过记录数据变更日志来实现。在事务提交前，记录预提交资源的变更，如果事务执行失败，则通过这些日志来回滚变更。
- 优点
  - 实现简单，对业务侵入性小。
  - 自动化程度高，无需手动编写补偿逻辑。
- 缺点
  - 性能开销相对较大，因为需要记录详细的数据变更日志。
  - 可能存在数据不一致的风险，尤其是在高并发场景下。

#### XA模式（两阶段提交）

- **原理**：XA是一种基于两阶段提交协议的分布式事务解决方案，它将事务提交过程分为准备阶段和提交阶段。
- 优点：
  - 强一致性保证。
  - 标准化协议，多数数据库管理系统支持。
- 缺点：
  - 性能开销大，第一阶段锁定资源，影响系统吞吐量。
  - 实现复杂，需要数据库和应用服务器的支持。

#### TCC模式（Try-Confirm-Cancel）

- **原理**：将业务操作分为Try、Confirm和Cancel三个操作，分别对应预留资源、确认执行和取消执行。
- 优点
  - 强一致性保证。
  - 业务逻辑清晰，易于理解。
- 缺点
  - 实现复杂，需要为每个操作手动编写对应的Confirm和Cancel逻辑。
  - 对业务代码侵入性较大。

#### Saga模式

- **原理**：将长事务分解为一系列短事务，每个短事务执行成功后，都会发布一个事件来触发下一个事务。如果某个事务失败，则执行一系列的补偿事务来回滚之前的操作。
- 优点
  - 适合长事务处理，提高系统吞吐量。
  - 可以实现微服务间的松耦合。
- 缺点：
  - 实现复杂，需要为每个操作编写补偿逻辑。
  - 一致性较弱，属于最终一致性。

**对比总结：**

| 特性         | AT 模式 | XA 模式  | TCC 模式        | Saga 模式            |
| ------------ | ------- | -------- | --------------- | -------------------- |
| 一致性       | 弱一致  | 强一致   | 弱一致          | 最终一致             |
| 性能         | 高      | 低       | 优              | 优                   |
| 可扩展性     | 差      | 差       | 好              | 好                   |
| 实现复杂度   | 低      | 中       | 高              | 高                   |
| 代码侵入性   | 低      | 低       | 高，编写3个接口 | 高，状态机和补偿代码 |
| 跨数据库事务 | 不支持  | 看数据库 | 支持            | 支持                 |

**适用场景：**

- **AT 模式：**适用于一致性要求高、参与者数量少、性能要求不高的场景。
- **TCC 模式：**适用于一致性要求较高、参与者数量多、性能要求较高的场景。
- **Saga 模式：**适用于一致性要求高、参与者数量多、性能要求较高、需要跨数据库事务的场景。
- **XA 模式：**适用于一致性要求高、性能要求较高、参与者数量少、数据库支持XA事务的场景。



### AT模式的实现过程

AT 模式是一种无侵入的分布式事务解决方案。在 AT 模式下，用户只需关注自己的“业务 SQL”，用户的 “业务 SQL” 作为一阶段，Seata 框架会自动生成事务的二阶段提交和回滚操作。

![](https://img-blog.csdnimg.cn/48ef896ab62e45e3bfa4dacc0f68b15b.png)

**模式原理**

在介绍AT 模式的时候它是无侵入的分布式事务解决方案, 那么如何做到对业务的无侵入的呢?

一阶段：

在一阶段，Seata 会拦截“业务 SQL”，首先解析 SQL 语义，找到“业务 SQL”要更新的业务数据，在业务数据被更新前，将其保存成“before image”，然后执行“业务 SQL”更新业务数据，在业务数据更新之后，再将其保存成“after image”，最后生成行锁。以上操作全部在一个数据库事务内完成，这样保证了一阶段操作的原子性。

![](https://img-blog.csdnimg.cn/e0402372ba51404db474b61a93e2260c.png)

二阶段：

提交：二阶段如果是提交的话，因为“业务 SQL”在一阶段已经提交支数据库， 所以 Seata 框架只需将一阶段保存的快照数据和行锁删掉，完成数据清理即可。

![](https://img-blog.csdnimg.cn/2c725957971343ed9a8018e669f508ba.png)

回滚：二阶段如果是回滚的话，Seata 就需要回滚一阶段已经执行的“业务 SQL”，还原业务数据。回滚方式便是用“before image”还原业务数据；但在还原前要首先要校验脏写，对比“数据库当前业务数据”和 “after image”，如果两份数据完全⼀致就说明没有脏写，可以还原业务数据，如果不一致就说明有脏写，出现脏写就需要转人工处理。

![](https://img-blog.csdnimg.cn/8b43ca61b5924fc590360b25bb8b4d6a.png)

AT 模式的一阶段、二阶段提交和回滚均由 Seata 框架自动生成，用户只需编写“业务SQL”，便能轻松接入分布式事务，AT 模式是一种对业务无任何侵入的分布式事务解决方案。 



# 分布式方案

## 分布式ID

### 分布式ID存在哪些方案？

#### UUID

32位16进制数字。

优点：不依赖第三方组件，在任务一台服务器上都能生成。使用简单，生成性能较高。

缺点：不具备含义，长度过长，数据库查询性能较低，不能范围查询，不能前台展示，影响问题排查和调试。

#### 数据库自增ID

所有的服务都使用一个单独的数据库来生成自增id。缺点是：高并发时可能引发单点故障，且影响全部服务的正常运转。

#### 号段模式

号段模式是在数据库的基础上，为了解决性能问题而产生的一种方案。他的意思就是每次去数据库中取ID的时候取出来一批，并放在缓存中，然后下一次生成新ID的时候就从缓存中取。这一批用完了再去数据库中拿新的。
而为了防止多个实例之间发生冲突，需要采用号段的方式，即给每个客户端发放的时候按号段分开，如客户端A取的号段是1-1000，客户端B取的是1001-2000，客户端C取的是2001-3000。当客户端A用完之后，再来取的时候取到的是3001-4000.
号段模式的好处是在同一个客户端中，生成的ID是顺序递增的。并且不需要频繁的访问数据库，也能提升获取ID的性能。缺点是没办法保证全局顺序递增，也存在数据库的单点故障问题。
其实很多分库分表的中间件的主键ID的生成，，主要采用的也是号段模式，如TDDLSequence

#### 基于Redis 实现

#### 雪花算法

#### 第三方ID生成工具



## 链路追踪

### 链路追踪有哪些实现

链路追踪的工具：如Google的dapper、twitter的zipkin、京东的hydra、大众点评的cat，以及开源的skywalking。

不管哪个实现，都要解决如下两个问题
1、生成一个全局的traceld
2、把这个traceld传递下去

生成Traceld

想要追踪一个完成的链路，就需要有一个标识来标记这次调用链，业内把他叫做traceld，一般会在入口处生成个全局唯一的traceld，比如说在HTTP的请求入口，在定时任务的调度入口等，生成一个traceld.

传递Traceld

在有了一个traceld之后，想要通过它把一次调用过程串联起来，那么就需要所有的系统间调用都得把他传递下去，这里面的调用包括了HTTP请求、RPC请求、MQ消息等，甚至还需要涉及到Redis、MySQL等等可能都需要进行传递。

所以，想要实现一个链路追踪，需要很多中间件一起配合才行，通常这个traceld会存放在RPC的请求头、HTTP的请求头、MQ消息的消息头中进行传递。

系统之间通过这种方式，系统内部也是需要传递的，一般都是用ThreadLocal来实现的，在接收到请求后会把这个traceld存储在ThreadLocal中，然后就能在当前线程中一直传递下去，并且在记录日志的时候取出来打印到日志中，在需要调远程的时候，取出来传递下去。
