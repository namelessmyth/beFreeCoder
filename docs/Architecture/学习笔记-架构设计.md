# 系统架构设计

## 架构设计原则

### 好系统是迭代出来的

在我们的技术生涯中，总是不断针对新的需求，去研发各种不同的系统，而不同的系统的设计是可以触类旁通的。在设计系统时，要根据项目背景、项目工期、不同的场景，做不同的设计。

项目背景举例，例如：做电商的项目和做金融的项目，侧重点就不一样，金融侧重精确性，电商侧重高并发。

一个系统并不是一下子就能设计的特别完美，我们都知道系统实施的过程中，一定是先解决当下最核心的问题，预测并发现未来可能会出现的问题，一步一步解决最头疼的问题。

例如：项目上线时的预估用户量就1000，那单机架构也是可以支撑的。同时可以预留未来升级的可能性。

也就是说系统设计其实是一个不断迭代的过程，在迭代中发现问题并修复问题。即满足需求的系统是不断迭代优化出来的，这是一个持续的过程，包括国内BAT巨头的系统，也是经过了这个历程。淘宝也是从单机开始的。

话又说回来，如果一开始我们就站在了巨人的肩膀上，在前人的经验上，有一个好的系统基础架构设计，未来就更容易达到一个比较满意的目标。

一个好的系统架构设计要做到，解决现有的需求，完成现有的目标，把控进度和风险，预测和规划未来，但是也不要过度设计，让系统在迭代中演进和完善。

在工作中，我们作为一个架构师，要鼓励团队成员积极主动沟通，并推动系统演进，另外也要思考二八定律，将有限的资源，用到更有价值的需求上，以最小化可行产品的方式迭代推进。

**总结** ：

- 好的系统都是迭代出来的。
- 先解决核心问题。
- 不要过度复杂化系统设计。
- 先行规划和设计是有必要的。
- 对现有问题有方案，对未来系统发展有预案。



### 无状态原则

#### 什么是无状态

无状态服务（Stateless service）是指：对单次请求的处理，不依赖于其他请求。

也就是说，处理一次请求所需的全部信息，要么都包含在这个请求里，要么可以从外部获取到（例如：配置文件，数据库，Redis），服务器本身不存储任何信息 ，也就是说：服务器是不保存请求的状态的，这就是无状态。

**反例**：处理这一次请求时还要去判断上一次请求。第2个请求依赖于第一个请求。这就是有状态的设计。

**案例**：每次请求都需要先鉴权，这算不算有状态？

例如：首先得先调用用户登录接口，登录成功有了token才能调用创建订单接口。

区分是否无状态，主要还是看服务器本地有没有存储token，如果没存那就是无状态的。如果存了，那就是有状态的。

#### 无状态原则的好处

由于服务器不保存任何信息，那么应用就能进行水平扩展。反过来，如果服务器存了请求的状态信息，那另一台服务器会因为就读取不到造成业务错误。

在实际生产环境中，一般是这样的：应用无状态，配置文件有状态。比如不同机房的服务，需要读取不同的数据源，那么这时候，就需要通过配置文件或配置中心来指定不同数据源的配置。



### 拆分原则

要做成一个什么样的系统？是大而全还是按照一定规则进行拆分的小系统？这个需要根据背景来权衡。

例如：做一个系统，用户量不大，就公司内部几百个人在使用，功能也很简单，并且开发者也就一个人，这时候就没必要进行系统拆分。

而如果是做一个类似于淘宝的秒杀系统，公司投入的资源很充足、业务功能复杂、用户量也特别大，那我们就需要进行系统拆分了。

总结拆分原则：高内聚、低耦合。

拆分前提：要对系统当前的状态有一个清晰的认识。基于一些重要信息去考虑拆分。可以考虑使用各种方式去埋点。例如：日志分析。可以在每个方法进入和退出时加入日志。或者安装监控系统。

**拆分维度**

#### **系统维度**

比如拆分成：商品系统、购物车系统、支付系统、优惠券系统等等。这一点需要和产品经理配合。

例如：拆分出支付系统后，这个系统可以给很多其他系统使用，其他公司都可以调用。

例如：用户系统，每次用户系统有改动，都要连带商品系统，订单系统一起发布，风险较大，维护较麻烦。

#### **功能维度**

在系统维度进行拆分后，再对一个系统进行拆分：比如优惠券系统，可以拆分成后台券创建系统、用户领券系统、用券系统等。

#### **读写维度**

首先要基于读写分析数据，根据读写比例特征进行拆分。比如有一些功能，都会进行大量的读写数据，然而读写比例失衡，比如说：读的量远远大于写，因此可以拆分成商品写服务、商品读服务。读服务就可以考虑使用缓存，来提升性能。如果某个服务写的量特别大时，需要考虑表分区、分库分表等等。

数据库的读写分离也可以看到读写分离的一种情况。

#### **切面维度**

比如一些大型的网站，全国各地的用户特别多，都来访问商品详情页，这样就可以分为cdn、页面渲染系统；cdn就是一个aop系统，类比于面向切面。在用户和实际服务中间拦一道。

CDN优化一般针对静态资源，对数据实时性要求不高。所以一般不用考虑数据库的分布式。

#### **模块维度**

根据公共基础模块或代码维护特征进行拆分，比如数据连接池模块、分库分表模块，综合消息队列。代码一般都是三层（，controller，service，dao。web service dao）。

一些大厂的会有基础架构组，专门给其他开发组提供二方库。例如：阿里，很多小公司现在用的开源框架，druid，rocketMQ就是这个组开发的单独模块。这些库在阿里内部项目使用时就在二方库，在其他公司使用就是三方库。



### 服务化原则

我们在开发项目的过程中，首先判断是不是单节点就能实现？

然后判断是不是简单的远程调用单个节点服务就可以实现？如果单个节点满足不了要求，那么节点集群是不是就可以？集群是不是用nginx做负载均衡就能满足？如果调用方越来越多，是否考虑，使用服务的自动发现 和 注册功能。

当服务越来越多的时候，服务越来越不好管理的时候，还需要考虑服务隔离，防止有的服务访问量大，把整个系统拖垮。那么继续发展，流量越来越大，我们还有进行限流，黑白名单，由于网络的不稳定，我们还需要超时重试故障补偿等功能，这些都会影响服务的质量。还有：熔断，限流，降级等。

总结：单个服务完成功能，调用单机远程服务，调用集群服务手动注册服务  自动发现注册服务  服务治理。



## 业务设计原则

本章节主要讨论的是每个业务功能基本都会涉及的设计原则。

### 防重原则

这里的防重指的是，防止重复提交。当请求响应时间变长，用户可能会多次点击同一个请求。

防重方法：不仅仅是前端要做防重处理，更重要的是后端。前端的防重有很多方式可以绕开。例如：新开一个浏览器页面，使用debug模式，通过api工具直接调用后台方法。

防重主要针对的是写操作，读不需要考虑防重。写操作也有些场景是不需要做防重控制的。例如：逻辑删除（数据库中根据某条数据的id将删除字段改成1）

首先系统必须能正确识别重复请求。例如：根据业务id判断，token判断等等。

针对重复请求做拒绝处理。



### 模块复用原则

当我们开发功能的时候，有复制粘贴欲望的时候，就应该思考一下，这个功能是否能复用。

总结起来，模块复用就是沉淀通用功能。例如：字典项功能，系统配置项功能，通知功能，定时任务功能，通用搜索功能。现在的很多低代码平台也是模块复用原则的一种体现。使用低代码平台时，只要涉及好业务对象，增删改查功能不用开发，通过配置就能使用。



### 可追溯原则

任何问题，要有据可查。这种有据可查不仅仅是写日志。有的系统还有历史记录功能，用户自己看历史记录都可以判断出来是不是自己操作问题。



### 反馈原则

系统的每个功能，但功能使用出现错误时，最好提供清晰明白的反馈信息。让用户一看就知道是自己哪里错了，怎么才能操作正确。

例如：用户名不存在，账号密码错误，用户无权限等等。

良好的反馈能很好地减少沟通成本，减轻开发人员沟通时间。



### 备份原则

备份主要是为了灾难恢复，让损失降低的到最小。

**代码备份**

Git，分支。备份所有发布版本，出现问题还能重新打包，部署。

**数据备份**

数据库的数据，可以使用运维备份（例如：数据库备份），操作记录也要注意备份（例如：日志，变更历史等等）。

**人员备份**

人员备份主要是为了不要因为某个人离职，对项目进度产生很大影响。

进行合理的代码review也是一种人员备份。避免出现某个开发思路很诡异或者随意使用团队没人会的第三方框架，导致新招来的交接人员可能会直接离职。

对于代码的低级问题对生产环境造成影响的。要对编写人，审核人，测试进行追责。

同时还可以采取**入库前代码review**。提交之后代码必须某个人审核通过才能入库。这样即使某个人离职了，审核人对他写的代码也熟悉。代码review工具推荐：[gerrit](https://zhuanlan.zhihu.com/p/21482554)。

在华为有这样一个挑刺制度，就是A写完代码，B来挑刺。B挑的刺越多绩效越高。还有一个制度叫做摇人，当你遇到功能不知道怎么开发时，可以通过摇人找人帮忙教你做。



## 软件质量衡量标准

衡量软件质量主要是为了从不同的维度，对某个人负责的项目进行评判。评判结果涉及相关人员的绩效，晋升。

既然要衡量，就涉及衡量标准。

### 功能

符合功能要求。

### 效能

投入多少，产出多少。

投入指的是投入多少时间，投入多少资源（人力，硬件资源），容量（数据库大小，网络带宽，事务吞吐量）

产出指的是系统能抗住多少并发，承载多少用户。

### 兼容性

软件的适应性有多广，是不是调用了一下第三方就崩溃了，或者多一个调用方就崩溃了。

### 易用性

在指定的条件下，能够很容易得让用户达到业务目的。

### 可靠性

容错，可恢复。多长时间可恢复。

### 安全性

用户输入一个非法字符系统就崩了。

### 可维护性

代码易读。功能设计符合公司规范，即使换个人来维护，也能轻易上手。

有的人可能会觉得软件可维护性越高，别人来能轻易上手，自己的可替换性就大就会显得自己不重要。

软件做得好，首先自己有成就感。然后别人看到了觉得你很牛。领导看到升职加薪机会更大，同事看到将来推荐你的机会更大。

### 可移植性

系统在一个地方用的很好，换一个地方也能用。



## 系统衡量指标

### 吞吐量

吞吐量是指单位时间内软件系统能接收和发出的数据量，主要体现系统处理请求的能力，这也是目前最常用的性能测试指标。

#### TPS

Transactions Per Second，每秒处理的事务数。TPS包括一条消息入和一条消息出，加上一次用户数据库访问。

QPS（每秒查询数）、TPS（）是吞吐量的常用量化指标，另外还有HPS（每秒HTTP请求数）。



#### QPS

Queries Per Second，每秒查询数。QPS主要针对查询服务性能指标，服务后面接的数据库中SQL的每秒执行条数。如果描述的是前端的每秒查询数，那就不包括插入、更新、删除操作了。不建议用QPS描述系统整体性能。



#### TPS&QPS

例如：将刷新淘宝页面当成一次事务，那这次事务中会有很多个查询（图片，商品信息）。具体要看事务是怎么定义的。

还有就是这里的事务和查询不要和数据库里的概念混淆起来，讨论QPS和TPS时并不和具体的底层实现强关联。而是在用户或者测试角度上的一件事和一次查询。

QPS和TPS并不能精确说明系统的性能高低，但可以用于衡量，程序或者配置修改后，系统的前后变化。



#### HPS

Hits Per Second，每秒HTTP请求数。Hit在性能测试中，一般都用来描述 HTTP Request。但是，也有一些人用它描述真正的客户在界面上的点击次数。



### 并发数

关于并发数有很多概念，例如：并发用户数，并发连接数，并发请求数，并发线程数。

#### 并发用户数

即：单位时间内同时使用系统功能的用户数。

有两种常见的错误观点。一种错误观点是把并发用户数量理解为使用系统的全部用户的数量，理由是这些用户可能同时使用系统；还有一种比较接近正确的观点是把用户在线数量理解为并发用户数量。实际上，在线用户不一定会和其他用户发生并发，例如正在浏览网页的用户，对服务器是没有任何影响的。但是，用户在线数量是统计并发用户数量的主要依据之一。

并发主要是针对服务器而言，是否并发的关键是看用户操作是否对服务器产生了影响。因此，并发用户数量的正确理解为：在同一时刻与服务器进行了交互的在线用户数量。

#### 并发连接数

并发连接数指的是客户端向服务器发起请求，并建立了TCP连接。每秒钟服务器链接的总TCP数量，就是并发连接数。

有了并发连接，用户不一定会进行操作，仅仅维持连接对系统性能影响还是比较小的。

#### 并发请求数

和TPS类似，指的是单位时间内对服务器发起请求的数量。

#### 并发线程数



### 响应时间

#### RT

Response Time，响应时间，简单理解为系统从输入到输出的时间间隔，宽泛的来说，他代表从客户端发起请求到服务端接受到请求并响应所有数据的时间差。一般取平均响应时间。 

[阿姆达尔定理](https://www.zhihu.com/tardis/zm/art/48022905?source_id=1005)：Gene Amdahl进行了一个富有洞察力的观察： 提升一个系统的一个部分的性能对整个系统有多大影响。这一观察被称为Amdahl's Law（阿姆达尔定律）

简单来说就是优化系统时应该第一考虑响应时间最长的那个。



### 可靠性指标

如果一个大系统有5个串联子系统构成，且每个子系统的可靠性都是99%，则系统整体的可靠性为5个99%相乘约等于95%。所以串联系统越多可靠性越低。

那如果改成并联，则是`1-(1-99%)*(1-99%)*(1-99%)*(1-99%)`，可以得出并联的情况下子系统越多越可靠。

并联的意思是一个系统的冗余从节点（集群）。A系统调用B系统时，B存在多个子节点，即使主节点挂了从节点会自动选举出新的主节点，系统依然可用。

这也是为什么可靠性要求越高，越要消除单点，化串联为并联。

生活案例：你出去买东西，一手交钱一手交货。你从网上买东西时，你先付钱，一段时间后才会给你发货，这就把交钱和交货分开了，它能不能发货不影响你付账。付钱的方式可以有多种：支付，微信，银行。发货的公司也可以有多家。但如果全中国只有一家送货公司，你可能就会担心付了钱可能会收不到货，选择一手交钱一手交货的方式了。



# 客户端优化

假设我们的系统，现在有1亿的用户手机端。那要如何优化才能使服务端支撑的了如此大的请求数？

首先，我们可以先考虑优化客户端，有一些处理可以尽可能的在这一亿的用户手机端完成

例如：app启动时，可以先从后端请求一些规则类的文件，然后存储在客户端。

然后后续需要做计算时，可以直接使用这些缓存的数据。例如：预估价格的场景，前提是允许预估价和实际价格不一致。

客户端分类：Android，iOS，浏览器。对于后端来说都是调用接口而已。只是资源的获取，处理，展示方式可能不同。

## 资源下载

资源：样式文件，脚本文件，图片，视频，文本等等。

**减少不必要的数据传输**。例如：不必要的cookie。cookie中的数据会和请求一起传给服务器。1个cookie可能1kb，那1亿个呢？某国民级应用有8亿用户。

案例：百度一开始接春晚时，前端要调用后端100个接口，后面优化至8个接口。春晚当天晚上可能有几亿用户使用，节约1kb也是一种很大的优化。

**压缩**。将资源压缩之后可以有效提供资源下载速率。客户端上传数据给服务器时也可以考虑压缩。

案例2：在用户上传图片时，除了存用户上传的原图，可以[自动生成图片的缩略图](https://blog.csdn.net/administratop/article/details/121553828)。当用户浏览图片时，可以先展示缩略图，用户进一步操作之后再展示原图。这也是一种压缩方式。淘宝的商品详情页，只有当鼠标放到图片上才会显示高清图。

JavaScript：删除无效字符，注释，1。减少体积，2。代码安全（让别人看不懂）。语义合并。

CSS：类似。语义合并。9行。原来10个按钮 10个样式，class 1个样式。

**http请求压缩**：

head中加参数：Accept-Encoding：gzip，deflate

表示客户端可以接受的压缩内容的格式。此时如果服务器支持压缩的话就会将响应内容压缩之后传给客户端

同时服务端响应中会加入：head: Content-Encoding:gzip。浏览器识别到这个响应后，就会利用自带的解压缩机制解压。

所以在服务端做一些压缩的操作。可以有效介绍数据量。

**减少请求次数**

客户端和服务器之间的连接需要经历3次握手，4次挥手。对于资源数目多、体积小，频繁创建http链接就消耗较大。

案例：如果一张雪碧图中包含了很多小图片，那可以将这些小图片合并成一张大图，通过样式文件background-postition来定位显示。

例如：矢量图可以通过记录坐标，然后通过：`<svg >`标签画出来。

js合并。将多个js文件打包成一个，一次下载。

使用base64图片也可以减少图片体积。在通过gzip压缩。

gzip 对文本文件的压缩  能压缩到原来的 40%以下。

将流量转移给第三方。OSS，图片，静态文件直接请求阿里云。



## 连接优化

### 长短连接

http1.0 不支持长连接，http1.1 默认长连接，

其实http根本没长短连接一说，连接是针对的tcp，所以上面的说法是错的。

http是针对请求和响应模式的，只要服务端给了响应，本次http连接结束。

TCP是一个双向的通道，他可以保持一段时间的不关闭，所以他才有长短连接。

http1.1在发请求的时候，如果在请求头中默认包含这个参数，connection:keep-alive。后端给前端返回的时候也带这个参数，那就能复用这个tcp的长连接。keep-alive: timeout=60s

测试：使用postman调用www.baidu.com，你会发现在headers中默认就会带上这个参数。

好处：减少了创建和销毁连接的消耗。

案例：请求一个网页（baidu.com），网页中包含css、js、html，如果每次都要建立新的连接。那这些资源也会每次重新下载

长连接并不会一直不关闭，只要超过header里设置的超时时间没有发送接收数据，就会自动关闭。

在chrome中按F12，然后点Network，观察后台的请求，如果这个是一个长连接，那每次刷新连接id是不会变化的。



### 长短轮询

例如：仓库库存字段，这个字段需要确保他在界面上始终显示最新的（即使用户没刷新页面）有哪几种实现方式。

写个js方法，不断的调用后台？去查询后台的库存是多少。这种方式能实现需求但是浪费了服务器的资源。这种时候就可以使用长轮询。

长轮询：客户端请求服务端，服务端如果发现数据没有变化，则将当前请求挂起一段时间。一直等到超时，如果有变化，才返回。这种方式大大减少了服务端和客户端的数据交互次数。降低了服务端一直疲于接收客户端请求的情况。

那服务端如何实现有变化才会返回结果给客户端？

1. 循环查询数据库，如果没有变化，睡一会儿继续查，直到查到有变化才返回。
2. 使用redis缓存。上面的方法虽然能实现，但是会给数据库造成压力。
3. 使用发布订阅模式。

### 双工通信

netty，websocket（简写：ws协议）。

双工通信：前后端 可以彼此 交互。

connection: keep-alive

keep-alive: timeout=60s



## 资源的缓存

通过缓存可以有效减少客户端访问服务端的次数，第一次从服务器获取后面就可以从缓存中读取。

缓存分类：页面缓存，节点间缓存，客户端本地缓存

页面的缓存

客户端、各级代理（中间的各个节点，例如：路由器，交换机，CDN，DNS，电信服务器）、这些节点都会对页面资源进行缓存。

如何控制：在headers中，Cache-Control:public

缓存控制有如下枚举值

pubic（服务器 响应中）: 各级都能缓存。

private（服务器 响应中）: 只能 客户端 缓存，中间各级不缓存。

no-cache（请求，响应都能设置)：可以缓存，但是不能直接使用缓存，要去服务端验证一下。

no-store（请求，响应都能设置)：哪都不要存。

缓存有效期：比较常用的是前2个。

max-age，单位：秒，缓存可以存活的时间。

s-maxage，单位：秒，在各级节点存活的时间，如果是客户端存储忽略。

max-stale，单位：秒，表示最大容忍的过期时间。

min-fresh，单位：秒，表示最小要留有N秒的新鲜度

**重新验证和加载的设置**

must-revalidate：告诉浏览器、缓存服务器，本地副本过期前，可以使用本地副本；本地副本一旦过期，必须去源服务器进行有效性校验。

proxy-revalidate：与must-revalidate作用相同，但它仅适用于共享缓存（例如代理），并被私有缓存忽略。。

no-transform: 不得对资源进行转换或转变。例如，非透明代理可以对图像格式进行转换，以便节省缓存空间或者减少缓慢链路上的流量。 no-transform指令不允许这样做。

only-if-cached: 表明客户端只接受已缓存的响应，并且不要向原始服务器检查是否有更新的拷贝。

**header使用案例**

Cache-Control: pulic, max-age=10,no-transform

**缓存更新不及时的处理**

更新文件名：修改版本号。例如：my-js.js。my-js-1.js。

url时间戳的变化，例如：getUser.do?t=202102010101010

客户端和服务器要达成一致。

### 验证缓存有效性

#### 基于文件最后修改时间

服务端：last-modified :  最后修改时间。

客户端：if-modified-since ：自己需要资源的时间。

你要我1个手机，我给你手机，手机贴标：时间戳。。304，不返回具体资源。200：返回具体资源。

如果客户端接收到的某个请求的服务器响应头设置了Last-Modified：

第一次请求：浏览器会记住响应头的Last-Modified；

第二次及以后请求：浏览器会携带保存的Last-Modified分别作为If-Modified-Since放入请求头中携带过去，以此到服务端验证此次请求的资源是否过期或更新；服务端进行判断，若过期或更新，则返回新的资源，否则返回空即可，节省服务端消耗。

在浏览器第一次请求某一个URL时，服务器端的返回状态会是200，内容是你请求的资源，同时有一个Last-Modified的属性标记此文件在服务期端最后被修改的时间，

格式类似这样：Last-Modified:Tue, 24 Feb 2019 08:01:04 GMT

客户端第二次请求此URL时，根据HTTP协议的规定，浏览器会向服务器传送If-Modified-Since报头，询问该时间之后文件是否有被修改过，
格式类似这样：If-Modified-Since:Tue, 24 Feb 2009 08:01:04 GMT

如果服务器端的资源没有变化，则自动返回304（NotChanged）状态码，内容为空，这样就节省了传输数据量。当服务器端代码发生改变或者重启服务器时，则重新发出资源，返回和第一次请求时类似。从而保证不向客户端重复发出资源，也保证当服务器有变化时，客户端能够得到最新的资源。

注：如果If-Modified-Since的时间比服务器当前时间(当前的请求时间request_time)还晚，会认为是个非法请求


#### 基于版本号

版本号字段：Etag。

客户端在请求中：if-none-match



## 页面解析优化

### 优化正常解析流程

元素

css样式文件，render tree，布局好，绘制。

js脚本

如果已绘制好的某个元素发生变动，会发生回流。重新计算每个元素的位置

重绘，将参数发生变化的后元素重新绘制并显示。

所以优化的目的就是要缩小回流和重绘的范围。

方法1：本来要调整dom的大小10次的，现在可以先将dom隐藏起来，等到第10次大小调整好了再显示出来。

方法2：将页面分成好几个块，局部某个块内的元素发生变化，只影响当前块，不会引起整个页面发生回流重绘。



### 虚拟DOM

虚拟DOM是一个JavaScript对象，它是对真实DOM的抽象表示。当数据发生变化时，前端框架（React，Vue）通过比较新旧虚拟DOM的差异，最终只更新必要的部分，从而避免了频繁地操作真实DOM而带来的性能问题。

#### 虚拟DOM优点

- 性能提升。虚拟DOM去更新真实DOM的时候是有算法优化的，只会更新必要的部分，减少了对真实DOM的更新次数。提升了性能。
- 更专注与业务。可以使得开发人员更加专注于业务逻辑的编写。业务数据变化之后相应的页面变化，可以由框架完成。
- 组件化开发。可以将一个完整的页面分成多个组件，每个组件都有自己独立的虚拟DOM，更够更好的复用和维护。
- 夸平台。虚拟DOM支持不同的浏览器，同一份代码可应用与多浏览器支持。

#### 虚拟DOM缺点

- 学习成本升高。需要学习新的前端框架与相关技术，并且了解虚拟DOM的操作API。
- 额外渲染成本。构建虚拟DOM客观需要额外的资源，在首次大量渲染虚拟DOM时，存在性能损耗。



## 页面加载优化

### 懒加载

懒加载指的是页面加载时，把加载内容拆分成多个部分，第一次尽量只加载满足业务需要的必要部分。其他部分可以等用户有进一步操作时再接着加载。懒加载的思想也可以用在后端。例如：单例模式中的懒汉模式。

这样回流和重绘的范围也会减少，只涉及页面已经展现的部分。

界面组件举例：

- 树形组件，默认只加载第一级内容，用户点了之后在加载下一级。
- 还有折叠面板，标签页，边滚动边加载页面等等。

h5  app 界面。

懒加载：仅仅加载 最基础的元素，以后，再根据用户的操作，进行局部加载。将原来一次性要加载的内容拆分成了多次加载。分流。

到了不得不看具体数据的时候，才调用后端。

注意：一些不会变化的或者用户并不关心数据实时性的部分，也不一定非要懒加载。



### 预加载

有一些页面之间存在普通的操作先后顺序，例如：页面B必然是通过页面A跳转过来的。用户点了页面A一般都会继续点页面B。

那在加载完页面A之后，可以提前加载页面B。这就是预加载。

预加载的内容可能是同一个域名也可能是不同域名。

相同域名：加载视频的时候，视频就会预加载到本地缓存中。

1。同一个域名下。

拉去资源

不同域名，例如：域名A，域名B，域名C

减少域名解析，此时：dns缓存。DNS预获取。

dns解析速度，被很多人忽视。蚊子腿也是肉。主流浏览器的DNS解析速度大概100ms左右

dns解析，可能会涉及多级DNS服务器的递归查询。对时间是消耗，我们想办法节省时间。

我们在当前页面，可以完成对下一个页面域名的解析，而在下一个页面直接使用预解析之后的结果。

**实现方式**

告知浏览器打开域名的预解析`<meta http-equiv="x-dns-prefetch-control" content="on">`

解析谁：`<link rel="dns-prefetch" href="//www.baidu.com">`

域名的预解析关闭：`<meta http-equiv="x-dns-prefetch-control" content="off">`

拉取资源：`<link rel="preload" href="xxxx.png" />`，`<link rel="prefetch" href="xxxx.js" />`

资源包含：音频，视频，embed，图片，js，css，

`preload`: 针对当前页面，更早的去下载资源，从而提升当前页面的资源加载速度。

`prefetch`: 针对下一页，如果下个页面存在比较大的资源，当前页面处理完，浏览器闲置的时候，会去加载该资源。

额外扩展：如果优化图片加载速度？图片->base64->放到 css文件里。



### 客户端数据库

意思是将部分数据存在客户端不去服务端获取。一个用户1k，1000w个用户可以减少服务端10G的流量。

cookie算一个：但他存在过期时间，且浏览器请求后端时会自动将cookie带上。所以cookie并不适合做客户端数据库。

使用谷歌浏览器访问百度首页，按F12再选择“应用程序”，可以看到有个storage项。下方还有很多子项。

local storage：这里的数据会长久存在。

session storage：这个要登录才会有。当session结束时会自动销毁。

web sql：是一个前端的关系型数据库。

cache storage，存的是请求和响应的值。key是请求，value是响应。

Application Cache，用于缓存整个页面，实现页面的离线访问。可以大大减少服务器的压力。

上面说的内容需要Html5的支持，也需要浏览器自身功能支持。

在android客户端中有sqllite。也可以实现类似关系型数据库的功能。

参考代码

```javascript
if(!window.localStorage){
    alert("浏览器不支持window.localStorage！");
}
var storage = window.localStorage;
// 写入a字段
storage["a"]=1;
// 写入b段
storage.b=2;
// 写入c字段
storage.setltem("c",3);

var a = storage.a;
console.log("a:"+a);
```



### 动静分离

首先得区分出什么是静态数据，什么是动态数据。

静态页面：是指互联网中，几乎不变的页面(或者变化频率很低)。

动态页面：是指互联网中，不同用户不同场景访问，都不一样的页面。

数据不仅包括传统意义上的页面，也包括不和访问者相关或者业务相关的个性化数据。

例如：一篇文章，无论谁来看都是一样的，虽然文章内容是从数据库中查询出来的。但属于静态数据。从数据库中查询的这部分也可以进行CDN优化和缓存优化。

区分出了动静数据，就可以进行动静分离的优化了：



#### 静态数据缓存

把静态数据放到离用户最近的地方。例如：浏览器，cdn，服务端的cache。

例如：打开谷歌浏览器和系统的任务管理器，逐步打开：百度，京东，淘宝，天猫这些大型网站，你会发现浏览器的内存占用逐步升高。然后关闭这些页面，浏览器的内存占用就会逐渐降低，这就是因为每个页面都会使用浏览器缓存。

例如：打开某一个京东的商品详情页：https://item.jd.com/100057333255.html，大家会发现这个url是一个html类型的请求。如果做动态应该是https://item.jd.com/page?itemId=123123，所以可以看出京东的商品详情页是做过静态化处理的。

参考实现：

当用户首次请求某个页面时，服务器会调用数据库将数据查询出来，然后会生成一个静态的html页面到服务器的目录中。

服务器例如：nginx，apache。然后将url和商品id做关联，第二次访问开始就可以直接访问静态资源，不用每次都访问数据库了。

在秒杀场景下，某个很热商品的并发访问量可能达到几百万以上。如果每次都直接访问数据库那会对数据库造成很大浪费。



#### 特殊元素分离

例如：虽然商品详情页大部分内容，谁来访问都一样。但还是会有一部分内容是需要动态显示的，可以将这部分内容分离出来。

例如：页面上部的已登录用户信息，购物车等等。总体思想还是尽可能的多做静态化。

静态化资源中，尽量将和用户个性化相关的东西去掉。例如：cookie



### 其他方案

统一缓存管理服务：缓存做分发。

或者使用CDN。

数据库查的 数据  +   样式文件   =  html文件。



# 网络优化

本章主要介绍请求从客户端发送出去经过各个节点到达服务端的这个过程中的优化。

```mermaid
flowchart LR
客户端-->DNS-->CDN-->服务端
```

## DNS优化

请求从客户端发出之后，第一个节点就是DNS。DNS的作用是将域名解析成为ip地址。它的结构可以理解成一个存储着域名和ip地址的分布式数据库。可以理解成一个web服务，挂着一个分布式数据库，提供crud功能。

[DNS图解（秒懂 + 史上最全）](https://blog.csdn.net/crazymakercircle/article/details/120521694)，[DNS域名详细解析过程](https://blog.csdn.net/bangshao1989/article/details/121913780)。



### 记录类型

A（Address）：域名和IP的对应关系

CName（Canonicial Name）：域名和域名的对应关系，也叫别名记录，相当于给A记录中的域名起个小名

NS（Name Server）：域名和能解析此域名的解析服务器的对应关系。例如：客户端拿者域名A去域名服务器B解析，但B无法解析，此时B会告诉A，服务器C能解析，让A继续去C解析。



### 域名

什么是域名呢？拿www.baidu.com举例

- 根域名 ：`.root` 或者 `.` ，根域名通常是省略的。上例完整的形式应该是 “www.baidu.com.”
- 顶级域名，如 `.com`，`.cn` ，`.org`，`.net`等。
  - com：公司企业，
  - cn：代表中国
  - org：非盈利组织，
  - edu：教育机构，
  - gov：政府部门，
  - int：国际组织，
  - mil：军事部门 ，
  - net：网络，
- 次级域名，如 `baidu.com` 里的 `baidu`，这个是用户可以注册购买的。
- 主机域名，比如 `image.baidu.com` 里的`image`，这个是用户可分配的。

结构：

```mermaid
flowchart TB
root["."]-->org
root-->edu
root-->com
root-->net
root-->gov

com-->baidu
baidu-->wwwb[www]
baidu-->map

com-->163
163-->www1[www]
163-->mail
```



### 域名服务器

有了域名结构，还需要有一个东西去解析域名，域名需要由遍及全世界的域名服务器去解析，域名服务器实际上就是装有域名系统的主机。由高向低进行层次划分，可分为以下几大类：

#### 根域名服务器

根域名服务器目前全球有13个（美国大概有10个，英国瑞典日本分别有1个）

所有的根服务器可以在这里查询：https://www.internic.net/domain/named.root

其中A是主根，其他的B，C，D。。。都是辅根。

注意：根域名服务器有13个，但实际的物理服务器不止13个，大概有1097个（2020年8月份统计），其中大概有100台服务器时一个ip地址。

我国虽然没有根服务器，但是我们有根服务器的镜像服务。

#### 顶级域名服务器

负责管理在该顶级域名服务器下注册的二级域名

#### 权限域名服务器

负责一个区的域名解析工作

#### 本地域名服务器

当一个主机发出DNS查询请求时，这个查询请求首先发给本地域名服务器

**关于分层， 需要注意的是:**

- 每个层的域名上都有自己的域名服务器，最顶层的是根域名服务器
- 每一级域名服务器都知道下级域名服务器的IP地址
- 为了容灾, 每一级至少设置两个或以上的域名服务器



### 域名解析流程

```mermaid
flowchart LR
name["客户端访问域名<br>www.baidu.com"]-->local
subgraph local
	direction TB
	browser["浏览器缓存"]
	-->|如果没有|os["操作系统缓存"]
	-->|如果没有|本地hosts文件
end
local-->root["根域名服务器"]-->|.com|top["顶级域名服务器"]-->IP
```

以上情况是教科书中写的流程。但实际情况如果每次找个ip都要走上述流程，效率并不高。所以实际情况会充分利用缓存，



浏览器缓存，如果浏览器缓存中没有则继续

操作系统，操作系统找hosts文件。如果没有则继续

LDNS，也会先找缓存。如果没有先找a.baidu.com的ns服务器。

如果没找到继续找baidu.com的ns服务器。找不到则才会找.com的根域名服务器。

如果实际情况并不会每次都绕道美国的根域名服务器。



### DNS优化方案

1. 提前做好DNS缓存。
2. 通过DNS做负载负载均衡。1个域名对应多个ip。多个请求过来，可以分别访问ip1，ip2，ip3的服务器。
   1. 缺点：增减服务时存在时效性问题。例如：多个服务器挂了一个，用户还能访问到挂的那个，就会访问报错。
   2. 负载均衡算法比较简单，无法做高级配置。



## CDN优化

网络是存在带宽的，如果一个要支持亿级流量的系统全国只有一个节点。当流量涌过来时，其实都到这个节点所在的机房就把这个地区的网络阻塞。例如：淘宝网早期，其流量能把一个一线城市的搞瘫了。所以亿级流量系统全国必须部署多个节点。

### 请求节点优化

- 将请求分配到多个节点，减少每个节点的并发数。
- 将请求分配到离用户最近的节点上。
  - 这里的最近不是指地理位置最近，而是网络拓扑最近。
  - 例如：在山东的某个城市，他和朝鲜的地理位置可能比访问山西更近，但实际不会访问
- 此类型优化只适合静态资源，动态资源即使放了cdn服务器还是得每次去源服务器获取最新的。



### CDN关键节点

源站：核心业务系统，所有信息的源头。

缓存（边缘）节点：存放静态资源。根据配置决定哪些资源要缓存。如果是动态资源还是会去源站获取。

同时缓存节点，启动时会对要缓存的静态进行初始化，提前内置好，并记录更新日期。在一定时间内不会去源站获取更新的值。超过这个时间则还是会去源站获取。查看是否有更新。

```mermaid
flowchart LR
客户端-->CDN-->|如果没有|源站
CDN-->|"如果有，直接响应"|客户端
源站-->CDN
```

### 节点数目

CDN节点数并不是越多越好。虽然CDN节点多了之后，会存在如下优点。

- 分担并发数，降低响应时间，减少网络拥堵。
- 中间环节变少，响应时间变少。

也存在如下缺点。

- CDN服务器越多，成本越高。
- CDN服务器越多，资源发布的成本越高。



### CDN设计

#### 用户来源

识别用户来源。根据ip地址查询用户地理位置信息。

#### 就近分发

例如：用户访问www.testB.com，此时我们购买了A公司的CDN服务。分别有北京和杭州2个节点。

此时，我们通过CName，将www.testB.com映射到www.testA.com

当请求被映射到www.testA.com后，服务器内部A会根据用户的来源信息，进行如下处理。

如果用户来源等于北京，则路由到北京CDN节点，否则路由到杭州节点。

注意：以上只是举例，具体的规则是可以定制的。

#### 内容缓存

在CDN服务器中可以放入配置规则。例如：/xxx.html /xxx.png 缓存到cdn服务器。 



### 总结

总体流程图

```mermaid
flowchart LR
client-->LDNS-->|CName|CDN["CDN供应商"]
subgraph cdnl["CDN节点"]
	direction TB
	CDN节点1
	CDN节点2
end

CDN-->|返回节点ip|LDNS
LDNS-->|离用户最近的ip|client

cdnl-->|动态内容|源站
源站-->cdnl

client-->|请求内容|cdnl
```

CDN在总体流程中，有2个作用，

地址获取。将客户端发送的域名解析成ip地址。

内容请求。处理客户端的内容请求。



## 多地址连接

主要用于将用户动态的请求做分发。

通过上文可知，CDN服务商那，维护着CDN节点列表，提供动态内容的源站列表。

方案

注册中心

规则中心

用户自己选择。例如：游戏选区，下载文件时让用户自己选清华镜像，阿里镜像等等。



## 代理

代理就相当于中间商,本来A和B是可以直接连接的,但是此时添加了一个C在中间,A跟B不直接连接,而是通过C作为中介进行连接。

一个完整的请求是由: client(客户端) -> proxy(代理) -> server(服务端) 组成。

在上文中，当客户端得到了确定的服务器IP。这个IP不一定是真正提供服务的机器，只是他们对外提供的统一的IP。



### 正向代理

正向代理: 顺着请求的方向进行的代理，即代理服务器它是由客户端配置为客户端服务，去请求目标服务器地址。例如：有些公司上班不让访问QQ或者微信，QQ或微信的服务器被网管封了。有些小伙伴就用代理软件，本地客户端请求代理网站（没有被网管拉黑），然后通过代理中转去访问QQ和微信的服务器。

```mermaid
flowchart LR
客户端1-->代理-->服务端
客户端2-->代理
客户端3-->代理
```

 正向代理的作用：

​    1. 访问原来无法访问的资源，如qq，微信，google

​    2. 可以做缓存，加速访问资源

​    3. 对客户端访问授权，上网进行认证

​    4. 代理可以记录用户访问记录（上网行为管理），对外隐藏用户信息


### 反向代理

跟正向代理相反,它是为目标服务器进行服务的。用户访问的代理ip是同一个，但是这个ip对应的服务器节点可能是多个。例如：nginx负载均衡。我们可以通过反向代理将很多并发用户的请求分流到不同的服务器节点上。

```mermaid
flowchart LR
用户1-->代理IP-->服务器节点1
代理IP-->服务器节点2
代理IP-->服务器节点3
```

反向代理如何识别用户请求？

我们知道，在[OSI网络7层模型](#OSI网络模型)中，http是属于第7层应用层，而tcp则是工作在第4层。

如果要在第4层tcp层实现反向代理，可以根据客户端的ip和端口进行转发。

如果要在第7层http层实现反向代理，方法会更多，可以根据客户端协议（http，ftp），请求的各种参数，方法（get，post），头（header里面的各种参数）cookie，正文里的各种参数，来进行转发。例如：可以判断用户请求的到底是png，jpg，mp4来进行转发。

**2种方式的区别**

在第4层实现，掌握的信息较少，实现起来更简单，运行效率更高。

在第7层实现，掌握的信息较多，可实现更复杂的需求，运行效率较低。

### OSI网络模型

参考文献：https://zhuanlan.zhihu.com/p/143654140

OSI网络七层模型如下，它将计算机网络体系结构划分为7层，每层都为上一层提供了良好的接口

![](https://img-blog.csdn.net/2018071408182610?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5HdWlHYW4)

![](https://img-blog.csdn.net/20170704164137407?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvU0NVX0NpbmR5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA)

**各层传输协议、传输单元、主要功能性设备比较**

| 名称       | 传输协议                                     | 传输单元         | 主要功能设备/接口                              |
| ---------- | -------------------------------------------- | ---------------- | ---------------------------------------------- |
| 物理层     | IEEE 802.1A、IEEE 802.2                      | bit-flow 比特流  | 光纤、双绞线、中继器和集线器 & RJ-45(网线接口) |
| 数据链路层 | ARP、MAC、 FDDI、Ethernet、Arpanet、PPP、PDN | frame 帧         | 网桥、二层交换机                               |
| 网络层     | IP、ICMP、ARP、RARP                          | 数据包（packet） | 路由器、三层交换机                             |
| 传输层     | TCP、UDP                                     | Segment/Datagram | 四层交换机                                     |
| 会话层     | SMTP、DNS                                    | 报文             | QoS                                            |
| 表示层     | Telnet、SNMP                                 | 报文             | –                                              |
| 应用层     | FTP、TFTP、Telnet、HTTP、DNS                 | 报文             | –                                              |

应用层 http ftp

表示层

会话层

传输层 tcp

网络层

数据链路层

物理层

4层反向代理：根据用户的ip和端口。

7层反向代理：根据用户协议，方法，头，正文参数，cookie。掌握更多的内容，更智能，效率低。

upstream：

access_by_lua_file.



### 两者的区别和联系

正向代理即是客户端代理, 代理客户端, 服务端不知道实际发起请求的客户端.


反向代理即是服务端代理, 代理服务端, 客户端不知道实际提供服务的服务端. 

正向代理中，proxy和client同属一个可访问的网络，对server透明。

反向代理中，proxy和server同属一个可访问的网络，对client透明。



识别用户的请求：



### 负载均衡算法

本章节主要讲的是，当请求到达反向代理服务器后，要通过什么样的算法将请求分配到多个服务器节点。

- 轮询：RR。Round Robin。就是挨个发。
    - 例如：第1个请求分到第1个，第2个请求分到第2个服务器。
    - 适用于所有服务器硬件都差不多的场景。
    - 实现原理，例如：使用请求中的用户id对服务器数量取模。这样同样一个用户每次都会分到同一个服务器。
- 加权：WRR。Weight Round Robin。按照权重不同进行分发，权重高的会分配到更多的服务器。

    - 实现原理：比如两个服务器，一个权重是6 ，另一个权重是4。总权重是10

    - 在1-10之间取随机数。如果取到1-6，那么找权重6的服务。如果取到7-10，找权重4的服务。
- 随机。如果有3台服务器，那就在1~3中去随机数。这种算法一般很少使用。
- Hash。原地址散列， Source  
    - 实现原理。例如：请求IP地址是a，对a进行hash，然后对应到服务器1.
    - 优势，只要服务器ip不变，服务器就不会变，便于session维护。
- 最少链接，Least connecitons。将请求路由到 最少链接的服务器上。
    - 例如：服务器A：10，服务器B：5，服务器C：3。那这个时候请求过来就优先放到服务器C。
    - 实现方案：可以使用redis的hash记录每个服务器正在处理的连接数，hset  key field value
    - field是服务器节点标识，value用连接数。





# 服务集群方案

## 并发和并行

并行：在某个时间点，多个任务进行。例如：我们可以同时用耳朵来听歌，然后用眼睛看书。

并发：在某个时间点，只有一个任务进行。但在一个时间段，有多个任务同时进行。

并发是抢资源的，并行是不抢资源的。只有多核cpu才可能存在并行。宏观上并行和并发将统称为并发。

把服务器主机想象成cpu，让一大堆任务在服务端可以并行执行的就是集群。

集群缺点：

如果使用了某些算法，可能出现数据不一致的问题。

例如：用户A先后发出2个请求，1个是修改1个是查询。且这2个请求还被分配到了不同的服务器节点上。那这时候可能就会查询错误。

所以使用服务器集群是需要注意一下问题：

注意幂等。（幂等：每次操作都是一样的结果）

注意服务器集群节点间的的数据共享。



## 无状态节点集群

做集群的时候，不要修改服务器自身内存的数据。而是使用共享数据存储。例如：redis，数据库。

无状态：请求到达服务器，携带了服务端所需要的所有参数，服务端的内存不存储所有跟请求相关的任何数据。

有状态：在服务端存储之前的请求信息，用于后面请求的处理。

集群一般用无状态。确保无状态，必须保证所有接口都是[幂等](https://zhuanlan.zhihu.com/p/425998517)的，系统内存中存储的数据不能发生变化。

可以考虑通过 公共存储，实现无状态。

**协作问题**

例如：每台服务器都会定时执行定时任务，发短信。要避免重复发短信。

**分布式锁**：在执行的时候锁定当前处理的记录，同时判断当前处理的这条数据是否存在锁，如果没锁才处理。

**外部唤醒**：将定时任务作为独立服务，由他来调用原来的反向代理服务去执行任务。这样1次只会有1台服务器被唤醒去处理任务。



## 单一服务节点集群

在某些系统中虽然存在很多服务器，运行这相同的程序，也组成了集群，但是不同的服务器处理的用户数据相互隔离，不互通。这种就是单一服务节点集群。例如：游戏项目。

这些系统一般对响应时间要求很高。需要将数据存在内存中。例如：用户的角色买了哪些装备，从位置1移动到了位置2，发射了一颗子弹。如果每次移动都存储数据库，响应时间根本跟不上。

所以登录游戏时一般要选服务器。尤其是实时对战类游戏。还会使用长连接。

实现关键：实现用户和服务器对应关系的映射。

手动选择服务器

用户id分配服务器

这种方式也解决了有状态的问题。

缺点是：容错性差。因为不同的服务器数据之间是隔离。一旦一台服务器崩溃，数据就会丢失，需要额外的去做数据备份



## 信息共享节点集群

多个服务连接同一个共享存储。

协作：

通过数据库自带的锁就能解决定时任务重复的问题。不需要用分布式锁。

缺点：

压力都到了共享存储上，程序性能会受到共享存储的限制。存储容量，读写性能。故障的单点，瓶颈所在。



## 信息一致节点集群

在上面的基础上，为了解决信息共享节点的缺点。可以让服务器节点拥有自己的独立存储。存储之间要做数据同步。

最常用的是读写分离。增删改请求落到一台存储上，查询请求查另一台存储。这两台存储要同步数据。

分流。

存储之间：数据一致性问题。

强一致：发生增删改后，只要事务提交成功了，就立即能查询到结果。

弱一致：最终一致。中间会有一段时间是不一致的，但最终数据同步成功后，会达到一致



## 分布式系统

上面讨论的服务器节点运行的都是同一套代码。但有的场景下同一套代码中不同的服务对服务器的性能要求是不一样的，有的功能占用的服务器CPU资源，有的是占用内存资源，有的是占用存储资源。我们可以将对性能要求不同的服务进行拆分。使得不同的服务器运行不同的程序代码。这就是分布式系统。

分布式系统存在的问题。

将服务拆分后就会存在相互调用的问题，如果是同一个业务拆分成多个服务，会存在分布式事务问题。那如何解决呢？

统一接口的定义。彼此当成黑盒。

微服务也是分布式系统的一种解决方案。

总结：

一个服务➡️服务分身（复制多份）➡️垂直切分。

```mermaid
flowchart LR
一个服务-->|"服务分身（复制多份）"|集群-->|垂直切分|分布式
```



## 高并发优化

高并发系统中的代码，就是我们普通的代码。例如：if ... else ... for ...

首先大量的堆机器，先把流量撑住，然后考虑架构设计。

项目上线 > 流量变大  > 加机器 > 优化架构(将一个巨石系统拆分) > 针对特殊请求沉淀技术（中间件）> 服务器节点越来越多 > devops

例如：一部分请求使用缓存，一部分使用MQ，

课程后面加代码实践。



## CAP

一个程序员越往上发展，设计和理论越显得重要。

一个公司的技术总监或者架构师写代码能力不一定有程序员强，但他们的架构思维，提供解决方案能力一定更强。

C：一致性，A：可用性，P：分区容错性，不可能同时满足，三者中选二挑一。（挑一指的是CA中只能挑一个满足）

### 一致性

数据的一致性，从什么角度去看？读、写。读出来的数据是否写入的数据一致。

一致性：写什么，就能读出什么。写：原子操作。

强一致性：写操作完成，后续的所有的读都能看到新数据。

弱一致性：写操作后，对该数据的读，可能是新值，也可能是旧值。

**最终一致性**：写后，读在一段时间内，可能读的是旧值，但是 最终，能读到新值。



### 分区容错性

分区

将多台服务器在网络上分成多个区域，每个区域包含一定数量的服务器。

例如：分区1网段：192.168.3.x，分区2网段：192.168.4.x，每个网段可包含多台服务器。

容错

如果发生网络错误，使得分区间无法数据互通，依然不影响系统的正常运行。

形成分区的原因只有网络故障这一种吗？

网络的8大谬误：

https://zhuanlan.zhihu.com/p/539266533

1 网络总是可靠的。例如：网管调整网络参数，网络设备故障或停电。

2 没有延迟。（发出请求后等待响应的时间）

3 带宽无限。

4 网络总是安全的。

5 网络拓扑不会改变。（网络节点设备和通信介质构成的网络结构）

6 只有一个管理员。

7 传输代价为0：

8 网络是同构的。

P 必须保证。即使网络出现问题，我们的系统也要能正常使用。

如何保证分区容错？

数据被复制到其他节点上。提前把数据给你。mysql，redis：slaveOf ，zk。



### 可用性

可用性：向未崩溃的节点发请求，总能收到响应。有数据就行，管它对不对。



### 为什么只能AP，CP？

例如：有2个服务器节点，分别存着a = 0，这时候其中一个被改成了 a=1。

如果要确保一致性，就必须让数据完成同步才允许查询，也就是说在完成数据同步之前，服务不可用。

如果允许查询就有可能查出来的数据不一致。这就是为什么A和P只能满足一个。

如何取舍？

看业务要求或者说容忍度。

（中间件去聊）

AP：web缓存，dns，cdn。（大部分情况下）

**比较好的策略**：

保证可用性和分区容错性，保证AP，兼顾C一致性（舍弃强一致性，保证最终一致性）。

电商场景：买东西送积分。先买东西，积分次日到账。红包同理。

如果保证强一致性，会对吞吐量造成负面影响。

A、B两系统，合起来完成一个业务。

A用10s，B用10s。一共 20s。10s。解耦方案：a事务结束后，发消息给MQ，B监听mq。

信息一致性方案

A和B事先建立数据同步机制，事务在a上完成后，自动同步给B。这个方案适合读多写少的场景。写得少意味着数据同步开销就小，就可以省下更多的资源给读。

前面所有内容：都是服务和服务之间的并发。接下来要介绍的是服务内的并发。



# 服务内并发

## 多进程

多进程的好处：每个进程之间，资源独立，具有很强的隔离性。但系统上一个进程出问题挂掉之后不会影响其他进程。

多进程方式启动java进程，`java -jar xxxx.jar`

如果物理机有限，但还是要考虑高可用，那就可以在一台服务器启多个进程多个端口来实现。

缺点：这种高可用方式一旦服务器挂了，上面的进程也会全挂。

例如：两台物理机：a、b、c三个服务。



## 多线程

案例1：一个方法大体的逻辑是先计算，然后等待io。其实在等待IO的过程中，还可以再起一个线程计算下一个任务的。因为在等待IO的过程中，cpu资源是闲置的。

案例2：出租车计费，可以按时长计费（1min多少钱），也可以按里程计费（1公里多少钱）。

这两种计算方式可以使用多线程，不一定要第一种计算完了，在计算第二种。可以使用future

目的：1 提高效率。

2 实现异步。提前释放主线程。（降低了响应时间，节省了保持客户端和服务连接的资源）

以下任务可以考虑使用异步线程实现。

- 日志记录。（磁盘操作）
- 第三方交互。
- 消息通知。
- 非主要业务。



## 线程数计算

### 公式一

线程数 = cpu核数  *  cpu利用率  * (1 + w/c)。

来源：《Java并发实践》

#### cpu利用率

取值：0-1之间。例如：50%。就是你想要多少CPU资源来处理你的任务

拿双核CPU举例：2个核心在1s内的时间占用分别是0.4s, 0.6s,   那CPU利用率就是(0.4+0.6)/2 = 50%

一般算线程数的时候，可以用100%。所以线程数 = cpu核数   * (1+w/c)。

#### w/c

w：等待时间，c：计算时间。wait/computer是等待时间和计算时间的比例

例如：2核CPU，等待2ms,  计算1ms，线程数  =  2*(1+2) = 6个线程。

直观的结论：等待时间相比计算时间的比例越大，线程数越高。

w/c：等待时间一般取决于程序中等待IO的时间，例如：写入日志，读取数据库等等。所以这部分时间越长说明CPU的空闲时间越长，就可以分配更多的线程数。IO密集型或者计算密集型也是这个计算公式，本质就是w/c比例不一样

可以通过在代码中打印日志来统计等待时间和计算时间。



### 公式二

线程数 = cpu核数/(1-阻塞系数)。

阻塞系数：计算密集型：大于等于0，IO密集型：小于1。意思是程序越是偏向IO密集型则线程数可以设置的越大

统一公式：

cpu核数 * (1 + w/c) = cpu核数/(1-阻塞系数)

可以得出 阻塞系数 = w/w+c。

**实际以压测为准。就是在压力测试下，系统可以稳定运行并达到性能要求。**

线程数，qps，机器配置。



# 缓存设计

前面章节回顾：

分流：到达服务之前，减少服务处理的请求数。

并发：到达服务之后，提升服务处理的请求数。

## 缓存设计

缓存设计的主要目的：

导流：将原本复杂的操作请求，引导到简单的请求上。前人栽树后人乘凉。

例如：将一大堆执行耗时的sql执行一次后，放入缓存，后面在查询就很快了。

空间换时间的一个做法。额外的缓存空间来节约每次查询的时间。

缓存类别：redis，memcached，localcache guava，客户端缓存

每个用户查询出来的数据都不一样要怎么缓存？可以使用用户id作为缓存的key。

例如：user_info_idxxxx  :  姓名，年龄，xxx。用getKey的内存操作来替换下面的SQL。

select * from user where id = xxx。 硬盘IO



### 缓存的收益

本章节主要讨论什么情况下可以使用缓存。使用缓存能够得到的收益。

缓存的收益：缩短功能的响应时间。复杂的数据库操作变成简单的缓存操作。

缓存位置：介于请求方和提供方之间。

缓存的成本：对缓存的读写，额外的缓存硬件资源占用。

缓存占用时间：计算key的时间，查询key的时间，转换值的时间。命中率P。

所有数据的查询时间 = 计算key的时间 + 查询key的时间 + 转换值的时间 + ( 1-p ) * 原始查询时间

当使用缓存之后的时间 远远小于 不用缓存的原始查询时间 才会使用缓存。

**适合缓存的功能**

- 耗时特别长的查询（复杂sql）
- 读多写少的功能。



## 缓存键设计

缓存是一个KV型的数据结构，这就意味着存在缓存键相互覆盖的问题。所以要尽量降低缓存键的碰撞概率。

单向函数：给定输入，很容易，很快能计算出结果，但是通过结果，很难计算出输入。

各种加密函数都可以被认为是单向函数，他们都具备以下特点。

正向快速，逆向困难，输入敏感（输入值的一点点变化都会导致输出值变化），冲突避免（不同的原始值不会有相同的计算结果）。

（md4，md5，sha-0，sha-1，已过时不安全。）

例如：sha-256，冲突的概率极低。

查询key的速度主要取决于：数据库的物理位置 （内存，硬盘）。

值类型：

序列化

将对象存入缓存时，想将其序列化处理，取出来时在反序列化。缺点是需要额外序列化的时间。优点是通用。存在redis或者其他缓存框架都支持。

对象

不需要序列化，但存在数据污染的问题。当某个客户端读的时候，另一个客户端可以对其进行操作，造成脏读。

总结：

无碰撞。高效生成。高效查询，高效转换。

上面所有：都被中间件提供的api封装了。

实际使用：`前缀_业务关键信息_后缀`。 **由公司统一制定规范**。

某用户的订单信息：user_order_idxxxx，user-order-idxxxx，user+order+idxxxx，

强烈不建议使用业务中可能出现的字符来作为key。



## 缓存更新机制

缓存角色：缓存使用方，暂存方（缓存），数据提供方（缓存数据的来源）

一般是当数据库提供方的数据存在更新了会去更新缓存中的数据。

主动的意思是缓存主动去取，被动的意思是，由其他方来改。

### 被动更新

被动：有效期到后，再次写入。

- 客户端 查数据，缓存中没有，从提供方获取，写入缓存（有一个过期时间t）。
- 在t内，所有的查询，都由缓存提供。所有的写，直接写数据库。
- 当缓存数据 t 到点了，缓存 数据  变没有。后面的查询，回到了第1步。

问题：在缓存的有效期内，如果数据库数据存在变化，则可能导致不一致。

适合：对数据准确性和实时性要求不高的场景。比如：商品关注的人数。



### 主动更新

为什么要主动更新？

例如：缓存内存着a=1，过期时间为10s，那在这期间，如果数据库改成了a=2，如果不主动更新数据，那客户端查出来的就不一致。

如何更新？

数据库操作：更新数据库

缓存操作：更新缓存，删除缓存

思路：根据上面的场景把所有场景罗列出来。保持一个定量，考虑围绕它的变量，这样才不会有遗漏。

#### 更新缓存，更新数据库

先改缓存，如果数据库异常回滚。但缓存是无法自动回滚的。此时客户端查询出来的数据0不一致。

此方案数据不一致的风险比较高，所以一般不采用。

#### 更新数据库，更新缓存

一般也不采用。先更新数据库，成功之后在更新缓存。

场景一

考虑并发的场景，一个事务要将0改成1，另一个事务要将1改成2。

如果事务1的请求被阻塞，事务2先去更新缓存，则最终结果会是1，和预期不符合。

场景二

如果更新完数据库之后，缓存中的值要通过比较复杂的计算才能去更新。而且此时也没有客户端要查询。就会存在性能浪费。还不如把缓存直接删除。将来需要查询的时候再去统计。

#### 删除缓存，更新数据库

一般不采用。大概率读比写快。当删除缓存后，查询请求如果在数据库更新好之前就过来，则缓存中存的就是旧值。

#### 延迟双删

延迟双删是在上面方案的基础增加一次删除缓存。当数据库更新好了之后，休眠一会儿再去把缓存删掉

休眠的时间可以自己根据查询时间来判断。例如：如果查询这个值的时间是3s，那就设置4s。

为什么延时双删一定要延时？

因为如果缓存中的这个值计算时间比较长，那在第一次删除后，如果来一个查询请求，这个查询请求可能会持续到第二次删除缓存之后，那查询出来的依然可能是旧值。

缺点是休眠的时间会导致系统吞吐量下降。可以将第二次删除缓存改成异步

延时双删的几步操作中某一步失败这么办？

第一次删除缓存。

如果异常，直接终止操作，返回错误就可以了。

更新数据库

如果异常，事务会回滚。其他请求过来查询会重新过来取出去，没问题。

第二次删除缓存

如果异常，可以在程序中捕捉异常重试删除。重试删除可以考虑使用中间件。

- 借用中间件：消息队列，重发消息。
- 系统外订阅：使用canal订阅MySQL的binlog。当发现数据被更新后，触发程序去删除缓存key。

多次删除如果都异常，可以给管理员发邮件。

使用这种方式会增加代码的复杂度，所以一般也不会采用。推荐下面这种。

#### 更新数据库，删除缓存

经常采用的方式。cache-aside模式。先更新数据库，再去删除缓存。

这种方式可能发生异常流程：

前提：缓存无数据。数据库有数据。缓存中如果有数据，在数据库更新完之前查到的是旧值，没问题。

事务A：查询，事务B：更新，按照下面的顺序发生。

1. A查缓存，无数据，去数据库读，此时是旧值。

2. B将数据库更新为新值，然后删除缓存结束。

3. A将旧值写入缓存。此时为旧值。


这个方案只要当对于同一个数据的读比写慢时才会发生，但这种概率很低。

一般只会在企业管理系统的复杂查询上发生。还要看用户的接受度，因为用了缓存之后已经可以极大提升查询速度了。使用缓存本身就存在延迟的。

如果非要解决，延时双删。再删除一次。



后面介绍的这两种方案，只有当并发很大，大到必须用缓存来当主存的场景。

#### Read/Write Through

以缓存中的数据为主。查询和更新都先操作缓存的值。通过其他机制来保证缓存和数据库的一致。

程序启动时，将数据库的数据， 放到缓存中，不能等启动完成，再放缓存中。启动完成后再放，可能会发生放到缓存中的数据是旧制的问题。

这种方案可能发生问题的场景：先更新缓存，在更新数据库的时候异常了，此时缓存中的数据就是不对的。

#### Write Behind

基于上面的方案，还是以缓存为主，只是使用异步机制来保证缓存和数据库的一致。

优点：降低了写操作的时间，提高了系统吞吐量。

缺点：如果缓存崩溃则更能丢失部分数据。



## 缓存清理机制

如何提升缓存命中率：尽可能多的将数据放入缓存。如果所有数据都放缓存，命中率 100%。

但实际情况是我们需要用有限的缓存空间，发挥最大的作用。所以就涉及到缓存清理了。

如何判断什么样的数据可以被清理呢？

读的时间频繁度，当清理一个数据的时候，发现它一直被访问，那我们就推断他未来也会被访问。

写入的时间。尽量清理写入时间较久的数据。

实现思路：

- 每当一个key被get的时候，记录一个系统时间。当清理的时候判断这个时间和当前系统时间的差值是不是超过一个阈值。
- 每当key被get的时候，就延长他的失效时间。那经常被访问的key就不会自动过期了。

### 时效性清理

给缓存设置一个过期时间，到期缓存自动清理。例如：redis，cookie

```sh
# redis 设置过期时间，单位秒
expire keyA 10
# redis 查看过期时间（秒，毫秒）
ttl test
pttl test
# redis 取消过期时间
persist keyA
# springboot 设置过期时间
redisTemplate.opsForValue().set("second","siweiWu",30, TimeUnit.SECONDS);

# cookie过期时间
set cookie   过期时间。
```

如果缓存不支持自动过期，可以按以下思路实现：

定时任务轮询。查询每个key的过期时间，是否快要到期，到期则delete

自动清理机制本质也是轮询，只是缓存自己实现了。



### 数目阈值式清理机制

判断缓存中的所有缓存key的数量，当达到一定值 ，对缓存进行清理。

阈值：根据自己的业务来定。例如：总量1g，每个1m，那最大就是1024个，当达到800个80%时就执行清理。

采取什么策略去清理：

fifo: 先进先出

```java
package com.example.cachetest;

import java.util.LinkedList;
import java.util.Queue;

/**
 * 数据阈值式清理
 */
public class CacheThresholdTest {
    public static void main(String[] args) {
        Queue<String> queue = new LinkedList<>();
        for (int i = 0; i < 4; i++) {
            //循环往队列中加值。
            setCache(queue,""+i);
        }
    }

    public static void setCache(Queue<String> queue, String cache){
        int size = queue.size();
        if (size >= 3){
            //当队列值超过3个时，将先进的值拉出来。
            queue.poll();
        }
        queue.add(cache);
        System.out.println("缓存中的值如下：");
        for (String q: queue) {
            System.out.println(q);
        }
    }
}

```

random：随机。随机删除缓存中的数据。一般很少使用。

lru：保护最近被访问的数据。清理长时间没访问的数据。

参考实现：可以将数据放入LinkedHashMap中。可以实现fifo和lru。

参考代码：

```java
package com.sjj.mashibing.algorithm.lru;

import java.util.LinkedHashMap;
import java.util.Map;
import java.util.Objects;

public class LinkedHashMapLru {
    public static void main(String[] args) {
        // lru就用true，fifo就用false
        LinkedHashMap<String,String> map = new LinkedHashMap<String,String>(5, 0.75F, true){
            @Override
            protected boolean removeEldestEntry(Map.Entry<String, String> eldest) {
                //容量达到5就移除元素
                return this.size() > 4;
            }
        };

        map.put("1","aa");
        map.put("2","bb");
        map.put("3","cc");
        map.put("4","dd");
        System.out.println("原始值："+Objects.toString(map));

        map.get("2");
        System.out.println("2 读取之后："+Objects.toString(map));

        map.get("3");
        System.out.println("3 读取之后："+Objects.toString(map));

        map.put("5","ee");
        System.out.println("5 加入之后："+Objects.toString(map));
    }
}

```

实现：k v。   map 一台服务器上能用。redis。

### 软引用清理

缓存其实是一种用空间去换时间的方法。在空间足够的前提下回尽量用更多的空间来提高缓存命中率p。也就是把更多的数据放到缓存中去。当空间不足时就需要采取适当的方法释放空间。

在java中有类似的机制：gc。识别出要清理的缓存，然后清除。

可达性分析，判断某个对象是否被gc root引用。对象存在四种引用类型。

强：只要是存在强引用，哪怕自己oom，也不清理。（不能用）

软：当空间不足的时候，会被回收。（可采用）

弱：只要被发现，不管够不够都会被清理。

虚：任何时候都可能被清理，形同虚设的意思，用于跟踪回收对象，清理相关资源。

参考Java的GC设计，把值放到SoftReference包装中。参考代码如下

```java
package com.gem.j2se.reference;

import java.lang.ref.ReferenceQueue;
import java.lang.ref.SoftReference;
import java.util.Date;
import java.util.HashMap;
import java.util.Iterator;
import java.util.Map;

/**
 * 使用软引用实现<br>
 * 建议使用如下参数来执行本案例：-Xmx60m -XX:+PrintCommandLineFlags -Xloggc:gc.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps
 *
 * @author namelessmyth
 * @version 1.0
 * @date 2024/1/6
 */
public class CacheSoftReferenceTest {
    public static void main(String[] args) throws Exception {
        System.out.println("开始执行：" + new Date());
        // 模拟缓存
        Map<Integer, SoftRefedStudent> map = new HashMap<Integer, SoftRefedStudent>();
        // 引用队列，存放软引用
        ReferenceQueue<Student> queue = new ReferenceQueue<Student>();
        for (int i = 0; i < 1000000; i++) {
            //创建很多个对象放入map中，模拟内存满的场景。
            Student p = new Student();
            map.put(i, new SoftRefedStudent(i, p, queue));
            //这个方法在内存没满还没开始回收的时候，返回的是空。
            SoftRefedStudent pollref = (SoftRefedStudent) queue.poll();
            //如果不为空，说明gc开始回收了，返回的是回收时的头对象。
            if (pollref != null) {
                //找出被软引用回收的对象，以key为标志，从map中移除
                System.out.println(new Date() + "回收对象：" + pollref.key);
                //从缓存中移除软引用。
                map.remove(pollref.key);

                Iterator<Map.Entry<Integer, SoftRefedStudent>> iterator = map.entrySet().iterator();
                while (iterator.hasNext()) {
                    Map.Entry entry = iterator.next();
                    if ((int) entry.getKey() == pollref.key) {
                        System.out.println("见鬼了居然还在：" + pollref.key);
                    }
                }
                System.out.println(i + "第2轮=====" + new Date());
            }
        }
        System.out.println("done");
    }
}

class Student {
    private String name;
    private int age;

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public int getAge() {
        return age;
    }

    public void setAge(int age) {
        this.age = age;
    }
}

class SoftRefedStudent extends SoftReference<Student> {
    public int key;

    /**
     * 当Student对象被回收后，SoftRefedStudent对象会被加入到queue中。
     * 第3个参数叫做ReferenceQueue，是用来存储封装的待回收Reference对象的
     */
    public SoftRefedStudent(int key, Student referent, ReferenceQueue<Student> q) {
        super(referent, q);
        this.key = key;
    }
}

```

### 清理总结

上面介绍了很多种缓存清理的方式，实际情况会混合着使用。

时效式清理+数目阈值

时效式清理能保证缓存存活一段时间后就被清理。防止：短期内，密集查询，导致缓存空间的急剧增大。

lru+软引用：保证热数据，最大限度的提高缓存命中率，p。

不建议：仅仅使用软引用。把缓存的清理交给GC，我们就失去了对它的控制。可能发生缓存击穿。

清理目的：节省空间，提升性能，提高缓存命中率，



## 缓存风险

虽然使用缓存存在诸多优点，但是在系统中，每增加一个环节，就会多一份风险。缓存也是有风险的。

### 缓存穿透

缓存中没有，数据库也没有。每次查询都会去数据库查询。给数据库造成压力。

解决方案：在第一次调用的时候，数据提供方返回一个空值，将空值放到缓存中。下次就不会再去查数据库。

布隆过滤器。

### 缓存雪崩

大量缓存突然失效，导致大量的请求，倾泻到数据库上，引起数据库压力骤增。

时效式清理：批量缓存，统一时间到期。缓存ttl=（固定时间，结合业务）+随机时间。

软引用清理：某个时间点，空间突然紧张，常用的缓存用强引用，不常用的用软引用。

### 缓存击穿

高频率的热点数据缓存，突然失效，大量请求倾泻到数据库上。

建议使用LRU。read write through，write behind.更新机制：无所谓。数据永远留在缓存当中。

### 缓存预热

read write through  or write behind虽然能避免缓存击穿。但在系统刚启动时，缓存中是啥都没有的。

不管是不是上面的2种方案，都建议在项目启动时给缓存进行预热：提前加载缓存，避免同一时间过期。

例如：计价规则，提前加载到缓存中。还有某些虽然不是热点数据，但是很多模块的公共数据。例如：字典

电商系统：热门商品，提前加入缓存。网约车中，计价规则提前加入缓存。

热门数据，加到缓存。

### 缓存风险的总结

遇到风险，分析原因，解决之。

原因：更新机制，清理机制。



## 缓存位置

缓存来源：因为CPU的速度远大于内存和硬盘，如果没有缓存，CPU将花费很多时间在等待数据，于是有了L1 L2 L3缓存。

数字越小越靠近CPU，速度越快，容量越小。L1和L2是每个核心单独的，L3是多个核心共享的。

缓存的读取过程：从最快的L1开始，如果没有命中则L2，依此类推。同时消耗的时间也会延长。

思考：如何避免cpu资源浪费？

- 减少CPU等待时间-增加缓存。

- 让CPU尽量多做事情-多线程。




### 级联系统缓存位置

级联系统之间，缓存如果越靠前，则性能越高，收益越大。要想系统性能好，缓存一定要趁早。

如下图：系统A调用系统B的接口，B又分别调用C和D的，则缓存放在A调用B的地方是最好的。

设计缓存的位置时应尽量避免哪里加起来简单就加在哪里。

~~~mermaid
flowchart LR
A-->|缓存放这里最好|B-->C
B-->D
~~~

#### 前置和后置

上例中。A是调用方，B是被调用方，如果缓存放在调用方A处，则为前置缓存。好处是因为一旦缓存命中，可以直接省去1次网络通信。

如果缓存放在被调用方B处，则为后置缓存。好处是可以为多个调用方服务。便于资源重复利用。

实际到底用前置还是后置，需要根据实际情况综合考虑。

如果只有1个调用方或者调用的网络通信时间占比较大，则考虑前置缓存。

如果调用方较多或网络通信时间占比较小，则考虑后置缓存。

也可以考虑两端都做。



### 客户端缓存位置

什么是客户端，就是直接和客户打交道的模块。例如：电脑浏览器，手机浏览器，android端，iOS端，微信端等等。

对于一个要支撑亿级流量系统，客户端的缓存尤为重要。

在我们的印象中，在一些大促的日子里，例如：双11，618，春晚等等。客户端总会提前升级一下。

那升级的是什么呢？充分利用客户端的资源去减轻服务端的压力。例如：将一些计算能转移的都转移到客户端，降低服务端调用次数。

规律：随着一个系统的流量不断增大，会将越来越多的工作放到前端去完成。

案例1：打车软件下单请求并不是最高的，而是预估价格。所以使用打车软件时，当用户选择完出发地和目的地后，前端就可以根据路线计算预估价了。某些客户看到预估价可能就不打了或者切换其他方案。

案例2：秒杀系统，一般不是下单请求量最高，而是商品详情页。所以商品详情页会做成静态文件（扣除动态部分）缓存在CDN中。

对于不重要的请求可以进行降级。例如：打车的时候，有部分数据可以用来分析用户的行为。平时可能会存到数据库中，但流量高峰时则会降级。

案例3：百度的凤巢系统，平时用来做广告推荐的，在百度参加春晚的那一年，也被降级了。因为春晚当天的流量非常大。

浏览器缓存：代码，`var storage = window.localStorage;`

浏览器cookie。如果非必要，不要用cookie做缓存。因为cookie会随着请求一起传给服务器。



### 静态缓存

静态缓存主要指的是客户端给出的一些静态数据的缓存。什么样的数据可以做成静态缓存？

1. 静态页面。例如：京东的商品详情页面用的就是html+一个商品ID。这种数据可以放在apache服务器中。
2. 通过数据库查出来的数据。如果每个用户查出来的都一样。例如：物流信息-省市区。那也可以缓存。


**凡是与用户个体无关的具有较强通用性的数据，都可以作为静态数据缓存。**

例如：新闻的页面，第一次访问时，是通过页面生成模版生成的。这个apache和nginx都可以做，然后作为静态数据缓存。后面如果有其他用户要访问相同的新闻页面，就可以直接读缓存。

对于已经缓存的页面，后台如果更改数据，可以通过cache aside将缓存删除。

对于用户不同，数据会变化的动态数据则不适合做客户端缓存。

### 服务器缓存

个性化的动态的不值得缓存。但是这些数据的生成有一个过程。如果过程中存在可复用的部分，则可以考虑缓存。

例如：电商系统中，我的介绍，地址信息，商品评价

### 数据库缓存

数据库耗时比较久。所以对数据库进行缓存对系统性能提升帮助还是比较大的。

怎么做？注意：redis不属于数据库自己的，属于数据之外的。

1. 冗余字段，减少关联查询。订单表里 id，有用户姓名，商品名称。

2. 中间表。通过中间表记录多张表的字段，例如：Oracle的物化视图。

3. 查询缓存：建议不用。mysql8抛弃了。缓存sql和结果，如果是相同的sql则直接从缓存中得到结果。
   1. 查询缓存仅适用于不常修改的场景。否则一旦表被改了，还要找到哪些缓存用了这个表，然后去更新。

历史表：将数据放到历史表中，以后的操作。例如：统计，可以查询历史表。相当于一次缓存。

新老数据如果要联合查询怎么办？新老数据可以放一起，统计数据单独剥离。



### 写缓存

前面讲的是读缓存，这章讲的是写缓存。写操作是调用方提供数据给被调用方。流量大的时候，被调用方可能会处理不过来。

所以写缓存的主要目的：削峰。不管调用方提供的数据有多少，尽量保证被调用方或者数据处理方的处理速率是固定的。

防止请求洪峰压垮系统。

#### 写缓存收益

比较采用缓存和不采用缓存的时间差异：

无缓存：数据处理方时间。例如：10s。

有缓存后：写缓存时间2s，从缓存读取数据的时间，数据传递时间，数据处理方时间（不变）。

按这样分析，用了缓存之后，只是增加了时间，那采取缓存的收益收益在哪里呢？

收益在于：从用户角度。写完缓存可以直接返回2s。所以减少了用户响应时间，提升了系统吞吐量。

#### 读缓存和写缓存区别

读缓存：用缓存的命中率，替换数据提供方的操作。能减少用户的请求时间，能减少系统的总处理时间。

写缓存：花费额外的时间，延迟数据处理方的操作，减少用户的等待。只能减少请求响应的时间，反而会增加系统的总处理时间。




#### 写缓存实践

利用redis的发布订阅。调用方将要写的数据发给redis，已订阅的数据处理方接收数据，进行处理。

MQ，原理同上。

数据库。先保存要处理数据，剩下的业务可以异步处理。


目的：只要能减少用户的响应时间。就OK。

**适合场景：请求峰谷值变化明显、对实时性要求不高的场景。**





# 职业规划

## 架构师

### 什么是架构师？

对于一个公司而言，架构师引领着整个公司的技术方向，架构师的眼界和高度决定了一个公司的技术高度。

对一个技术团队而言，架构师的决策和技术方案，影响着工程师的开发模式和开发工作量。

一个好的架构师能让团队用最少的工作达到最好的效果。就是事半功倍。一个差的架构师可能就是事倍功半。

一个好的架构师是一个公司的宝贵财富，一个差的架构师是一个团队的噩梦。



### 架构师分类

首先架构师并没有全球统一的分类标准。不同公司，不同国家对架构师的分类可能都是不一样的。

#### 按照职责分

架构师分为：产品架构师，开发架构师，运维架构师。



**产品架构师**

负责整个产品的技术架构，当产品的业务规划和规则确定后，产品架构师需要开始设计产品，确定产品模块之间的架构，

和运维团队确定用户数，PV数（PageView，网页访问量）商品数，订单量等等非功能性的运维指标。

和产品经理确定功能需求，功能模块的划分。

和项目经理确认开发资源，测试资源。每种资源能安排多少人到项目上。

收集到所有相关信息后进行整体的架构设计。然后给销售，运营，开发，测试，运维确定目标。

还需要参与到产品的整个生命周期中去。从无到有到最后上线，版本升级。

这种架构师比较高端。



**开发架构师**

1. 负责开发基础框架，公共组件，通用服务等等可以让很多人使用的功能。
2. 对于开发成果需要承担海量数据存储，高性能，高并发，高可用等三高问题。
3. 负责核心功能开发。项目组疑难问题解决。以及其他具有技术挑战性的工作。



**运维架构师**

负责网络存储等运维工作，例如：负载均衡，多个数据库，多个存储，多个消息队列，多个日志如何归类如何存储等等。



#### 按照工作分

架构师分为：普通架构师，极客型架构师，助人型架构师，扫地僧架构师，布道型架构师。

**普通架构师**

负责系统架构设计，框架的实施落地，后期技术演化重构，核心代码编写等

**极客型架构师**

满足普通架构师的要求，对于某些技术领域有特别深入的研究，达到精通的程度。例如：阿里P7

**助人型架构师**

当团队成员遇到困难时，需要给予一定的帮助，帮助其他成员快速成长。

**扫地僧架构师**

每当系统出现故障，一般人搞不定时都需要他们出马。他们可能是随着公司的开发发展到壮大一直都在，所以他们对公司的整体技术架构非常清楚，所以他们是公司的定海神针。

**布道型架构师**

存在较好的个人影响力，以及坚定的技术信仰，乐于分享，在公司内部能推动推广自己的技术主张。这种类型的架构师也反面教材，也有一部分放弃学习，停止成长，出于自身的局限最终成为一个忽悠型架构师，阻碍公司发展的。



#### 关注点

### 功能



### 非功能



### 团队与组织管理



### 产品运营



### 产品未来



## 进大厂

### 大厂介绍

一线大厂：bat，字节，美团，华为，微软

二线大厂：京东(836)、网易(680)、拼多多(610)、百度(480)、快手(380)、携程(250)、贝壳(150)、滴滴(100)



### 面试内容

#### 算法

美国的大厂对于应届生基本主要考察这个。这个是程序员的基本功，相当于易筋经，不是短期突击就能突击出来的。



#### 架构设计

这是另一个国外大厂考核有经验程序猿的主要内容。也是需要长期积累的。

同样是设计一辆车，张三设计出来的可能是奥拓，李四设计出来的可能是奔驰。虽然功能类似都是设计理念，未来扩展，质量并不相同。

会通过一些实际的案例，要求面试者进行架构设计来达到业务要求。知识包括：设计模式，框架源码，技术选型等。

例如：设计架构支持春节红包雨，30秒内抢1亿的红包。红包数量：1000万，用户数：3000万。每个用户只能抢成功1次。



#### 面试八股

包含面试的常见内容，不同的厂可能问的内容不一定一样。但是这部分知识积累的越多越好。

例如：JVM，并发优化，Redis，MQ，设计模式，Spring源码



#### 项目应用

主要是看简历中项目经验中对于考察知识的实际应用。前面答得好



#### 加分项

这部分内容有的话加分，没有影响也不大。例如：云原生，大数据，AI。



## 大龄问题

